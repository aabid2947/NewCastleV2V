{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nda00J9R4Lu0",
        "outputId": "86c7a726-455e-453a-d8b6-22183d2019d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l2Mk2cvgMo6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236f026e-4786-4ce5-a328-4d4d0f201058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbfKrsNF5roK",
        "outputId": "06e35df7-44fd-4739-fed7-4ac5a960a1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Number of Neighbors within a specific radius\n",
        "\n",
        "Purpose:\n",
        "Count nearby vehicles within a 10m radius using spatial indexing.\n",
        "Key Components:\n",
        "\n",
        "KD-Tree Optimization: Enables O(n log n) neighbor searches instead of O(n²).\n",
        "\n",
        "Timestamp Grouping: Processes vehicles existing at the same moment.\n",
        "\n",
        "Self-Exclusion: Removes the vehicle itself from neighbor counts.\n",
        "\n",
        "Error Handling: Validates required columns before processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "yd5mtlav46DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Number of Neighbors within a specific radius (Optimized with KD-Tree) ---\n",
        "def calculate_neighbors_count(df, distance_threshold=10):\n",
        "    \"\"\"\n",
        "    Calculate the number of neighbors within a specified distance threshold\n",
        "    for each vehicle at each timestamp based on their positions using a KD-tree.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing vehicle data with 'Time (s)', 'Vehicle ID',\n",
        "                           'Position X (m)', and 'Position Y (m)' columns.\n",
        "        distance_threshold (float): The maximum distance in meters to consider a vehicle a neighbor.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: A Series containing the number of neighbors for each row,\n",
        "                   aligned with the input DataFrame's index.\n",
        "    \"\"\"\n",
        "    neighbor_counts = pd.Series(0, index=df.index) # Initialize Series for neighbor counts\n",
        "\n",
        "    # Ensure necessary columns exist\n",
        "    required_cols = ['Time (s)', 'Vehicle ID', 'Position X (m)', 'Position Y (m)']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        missing = [col for col in required_cols if col not in df.columns]\n",
        "        print(f\"Error: Required columns for neighbor calculation are missing: {missing}. Skipping neighbor count calculation.\")\n",
        "        return neighbor_counts # Return all zeros if columns are missing\n",
        "\n",
        "    # Process data for each timestamp\n",
        "    timestamps = df['Time (s)'].unique()\n",
        "    # print(f\"Processing {len(timestamps)} unique timestamps for neighbor count...\") # Can be verbose\n",
        "\n",
        "    # Group by timestamp for efficient processing\n",
        "    grouped_by_time = df.groupby('Time (s)')\n",
        "\n",
        "    for ts, vehicles_at_ts in grouped_by_time:\n",
        "        if len(vehicles_at_ts) <= 1:\n",
        "            # If 0 or 1 vehicle, no neighbors to calculate for this timestamp\n",
        "            continue\n",
        "\n",
        "        # Extract positions for KD-tree and get original dataframe indices\n",
        "        # Ensure positions are float type for KDTree\n",
        "        positions = vehicles_at_ts[['Position X (m)', 'Position Y (m)']].values.astype(float)\n",
        "        original_indices = vehicles_at_ts.index.tolist()\n",
        "\n",
        "        # Build KD-tree\n",
        "        tree = KDTree(positions)\n",
        "\n",
        "        # Query the KD-tree for neighbors within the distance threshold\n",
        "        # query_ball_point returns a list of lists, where each inner list contains the indices\n",
        "        # of neighbors for the corresponding point in the input positions array.\n",
        "        # The indices are relative to the positions array (0 to len(vehicles_at_ts)-1).\n",
        "        neighbor_indices_list = tree.query_ball_point(positions, distance_threshold)\n",
        "\n",
        "        # Count neighbors for each vehicle at this timestamp and update the Series\n",
        "        for i_local, original_df_index in enumerate(original_indices): # Iterate through the original indices\n",
        "            # Get the indices of neighbors for the i_local-th vehicle in the vehicles_at_ts subset\n",
        "            neighbors_relative_indices = neighbor_indices_list[i_local]\n",
        "\n",
        "            # Exclude the vehicle itself from its neighbors list\n",
        "            # The query_ball_point includes the point itself, so we need to remove index i_local\n",
        "            valid_neighbors_relative_indices = [idx for idx in neighbors_relative_indices if idx != i_local]\n",
        "\n",
        "            numNeighbors = len(valid_neighbors_relative_indices)\n",
        "\n",
        "            # Update the neighbor_counts Series using the original index\n",
        "            neighbor_counts[original_df_index] = numNeighbors\n",
        "\n",
        "    # print(\"Neighbor count calculation complete for this file.\") # Can be verbose\n",
        "    return neighbor_counts"
      ],
      "metadata": {
        "id": "2UhE2z9gX9Cp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Function to Convert Lat/Long to X/Y\n",
        "\n",
        "Purpose:\n",
        "Convert GPS coordinates to local Cartesian coordinates for distance calculations.\n",
        "Key Components:\n",
        "\n",
        "Equirectangular Projection: Approximates Earth as a cylinder for small areas.\n",
        "\n",
        "Reference Point: Uses dataset's mean lat/long as (0,0) origin.\n",
        "\n",
        "Earth Radius: 6,371 km (standard average value)."
      ],
      "metadata": {
        "id": "Vl_jbYk75Bbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Function to Convert Lat/Long to X/Y ---\n",
        "def latlong_to_xy(lat, long, ref_lat=None, ref_long=None):\n",
        "    \"\"\"\n",
        "    Convert latitude and longitude to X/Y coordinates in meters\n",
        "    using a reference point as origin (0,0). Uses equirectangular projection\n",
        "    for simplicity, which is suitable for small areas.\n",
        "\n",
        "    Args:\n",
        "        lat (pd.Series): Series of latitude values.\n",
        "        long (pd.Series): Series of longitude values.\n",
        "        ref_lat (float, optional): Reference latitude for the origin. Defaults to the mean latitude.\n",
        "        ref_long (float, optional): Reference longitude for the origin. Defaults to the mean longitude.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (x_coords, y_coords) in meters.\n",
        "    \"\"\"\n",
        "    if ref_lat is None:\n",
        "        ref_lat = lat.mean()  # Use mean latitude as reference\n",
        "    if ref_long is None:\n",
        "        ref_long = long.mean()  # Use mean longitude as reference\n",
        "\n",
        "    # Earth radius in meters (using a common average)\n",
        "    R = 6371000.0\n",
        "\n",
        "    # Convert degrees to radians\n",
        "    lat_rad = np.radians(lat)\n",
        "    long_rad = np.radians(long)\n",
        "    ref_lat_rad = np.radians(ref_lat)\n",
        "    ref_long_rad = np.radians(ref_long)\n",
        "\n",
        "    # Calculate X (East-West position) using equirectangular projection\n",
        "    x = R * np.cos(ref_lat_rad) * (long_rad - ref_long_rad)\n",
        "\n",
        "    # Calculate Y (North-South position) using equirectangular projection\n",
        "    y = R * (lat_rad - ref_lat_rad)\n",
        "\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "m_gKom1EYAnJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function\n",
        "\n",
        "Workflow:\n",
        "\n",
        "Input: Raw vehicular CSV data\n",
        "\n",
        "Processing:\n",
        "\n",
        "1.Time normalization\n",
        "\n",
        "2.Coordinate conversion\n",
        "\n",
        "3.Neighbor analysis\n",
        "\n",
        "4.Risk assessment\n",
        "\n",
        "Output: Enhanced CSV with risk labels\n",
        "\n",
        "Error Handling: Robust validation at each stage"
      ],
      "metadata": {
        "id": "kKjOHPs25Fbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFvQwWslpNfw",
        "outputId": "42a80abf-429a-419e-bfd3-0f98f6a86b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to find CSV files from: /content/drive/My Drive/Lokm/simulation_results/Dataset matching pattern 'vehicular_dataset_*.csv'\n",
            "Files found by glob: ['/content/drive/My Drive/Lokm/simulation_results/Dataset/vehicular_dataset_2025-01-07.csv']\n",
            "\n",
            "Found 1 CSV files. Processing and saving to new files...\n",
            "\n",
            "--- Processing file: vehicular_dataset_2025-01-07.csv ---\n",
            "Successfully loaded 4320000 rows.\n",
            "Processing timestamp...\n",
            "Converted 'Time (s)' to seconds since epoch (numeric).\n",
            "Converting lat/long to X/Y coordinates...\n",
            "Added 'Position X (m)' and 'Position Y (m)' columns.\n",
            "Calculating Number of Neighbors (10m)...\n",
            "Added 'Number of Neighbors (10m)' column.\n",
            "Applying risk labeling rule...\n",
            "Risk labeling complete.\n",
            "Generated Risk Labels for vehicular_dataset_2025-01-07.csv: 4319970 safe (0) and 30 risky (1) instances\n",
            "Warning: Overwriting existing column 'Number of Neighbors (10m)' in vehicular_dataset_2025-01-07.csv.\n",
            "Warning: Overwriting existing column 'Risk Label' in vehicular_dataset_2025-01-07.csv.\n",
            "Saving updated data to NEW file: /content/drive/My Drive/Lokm/simulation_results/Dataset/vehicular_dataset_2025-01-07_with_risk_label.csv\n",
            "Successfully saved updated data for vehicular_dataset_2025-01-07.csv to vehicular_dataset_2025-01-07_with_risk_label.csv.\n",
            "\n",
            "--- Script Execution Finished ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "from scipy.spatial import KDTree # Import KDTree for efficient neighbor search\n",
        "import numpy.linalg as la # For calculating Euclidean distance efficiently\n",
        "import traceback # Import traceback for detailed error reporting\n",
        "\n",
        "# --- Configuration ---\n",
        "# Directory containing the multiple Kaggle dataset files (assuming CSV format)\n",
        "KAGGLE_DATASETS_DIR = 'Drive Dir Location' # <<< ADJUST THIS PATH\n",
        "\n",
        "# File pattern to search for within the directory\n",
        "KAGGLE_FILE_PATTERN = 'vehicular_dataset_*.csv' # Matches files like vehicular_dataset_YYYY-MM-DD.csv\n",
        "\n",
        "# Suffix to add to the original filename for the new processed file\n",
        "OUTPUT_FILE_SUFFIX = '_with_risk_label.csv' # Example: vehicular_dataset_2025-01-06_with_risk_label.csv\n",
        "\n",
        "# --- Column Mapping (Map Kaggle dataset columns to necessary columns) ---\n",
        "# IMPORTANT: These keys MUST match the EXACT column names in the downloaded Kaggle CSV files.\n",
        "# The values are the names used in this script.\n",
        "COLUMN_MAPPING = {\n",
        "    'VehicleID': 'Vehicle ID',\n",
        "    'Timestamp': 'Time (s)',\n",
        "    'Latitude': 'Latitude',\n",
        "    'Longitude': 'Longitude',\n",
        "    'Speed': 'Speed (m/s)',\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Main Execution for Risk Labeling and File Saving ---\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Start of Main Try Block ---\n",
        "    try:\n",
        "        full_pattern = os.path.join(KAGGLE_DATASETS_DIR, KAGGLE_FILE_PATTERN)\n",
        "        print(f\"Attempting to find CSV files from: {os.path.abspath(KAGGLE_DATASETS_DIR)} matching pattern '{KAGGLE_FILE_PATTERN}'\")\n",
        "\n",
        "        # Find all CSV files matching the pattern\n",
        "        csv_files = glob.glob(full_pattern)\n",
        "\n",
        "        print(f\"Files found by glob: {csv_files}\") # Print files found\n",
        "\n",
        "        if not csv_files:\n",
        "            print(f\"No CSV files found matching '{KAGGLE_FILE_PATTERN}' in '{KAGGLE_DATASETS_DIR}'.\")\n",
        "            print(\"Please ensure your dataset files are in this directory and match the pattern.\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        print(f\"\\nFound {len(csv_files)} CSV files. Processing and saving to new files...\")\n",
        "\n",
        "        for csv_file_path in csv_files:\n",
        "            file_name = os.path.basename(csv_file_path)\n",
        "            print(f\"\\n--- Processing file: {file_name} ---\")\n",
        "\n",
        "            # --- Start of File Processing Try Block ---\n",
        "            try:\n",
        "                # Load the dataset\n",
        "                df = pd.read_csv(csv_file_path)\n",
        "                print(f\"Successfully loaded {len(df)} rows.\")\n",
        "\n",
        "                # --- Select and Rename necessary columns based on mapping ---\n",
        "                cols_to_select = list(COLUMN_MAPPING.keys())\n",
        "\n",
        "                missing_cols_in_kaggle = [col for col in cols_to_select if col not in df.columns]\n",
        "                if missing_cols_in_kaggle:\n",
        "                     print(f\"Error: Required columns for processing NOT found in {file_name}: {missing_cols_in_kaggle}. Skipping this file.\")\n",
        "                     continue # Skip to the next file\n",
        "\n",
        "                # Create a copy to work with and add new columns\n",
        "                df_processed = df[cols_to_select].copy()\n",
        "                df_processed.rename(columns=COLUMN_MAPPING, inplace=True)\n",
        "\n",
        "                # --- Data Preprocessing ---\n",
        "                # 1. Convert timestamp to numeric (needed for grouping by time in neighbor calculation)\n",
        "                print(\"Processing timestamp...\")\n",
        "                try:\n",
        "                    df_processed['Time (s)'] = pd.to_datetime(df_processed['Time (s)'])\n",
        "                    if df_processed['Time (s)'].dt.tz is not None:\n",
        "                        df_processed['Time (s)'] = df_processed['Time (s)'].dt.tz_localize(None)\n",
        "                        # print(\"Removed timezone information from 'Time (s)'.\") # Can be verbose\n",
        "                    df_processed['Time (s)'] = df_processed['Time (s)'].astype(np.int64) // 10**9 # Convert nanoseconds to seconds\n",
        "                    print(\"Converted 'Time (s)' to seconds since epoch (numeric).\")\n",
        "                    time_conversion_successful = True\n",
        "                except Exception as e:\n",
        "                    print(f\"Error converting 'Time (s)' to numeric in {file_name}: {e}.\")\n",
        "                    traceback.print_exc()\n",
        "                    print(\"Skipping neighbor calculation and risk labeling for this file due to time conversion failure.\")\n",
        "                    time_conversion_successful = False\n",
        "                    # Add placeholder columns to prevent errors if we continue\n",
        "                    df_processed['Position X (m)'] = 0.0\n",
        "                    df_processed['Position Y (m)'] = 0.0\n",
        "                    df_processed[f'Number of Neighbors (10m)'] = 0\n",
        "                    df_processed['Risk Label'] = -1 # Use a value outside 0/1\n",
        "                    # We will still attempt to save the file with placeholders if possible\n",
        "\n",
        "\n",
        "                # 2. Convert latitude/longitude to X/Y coordinates (needed for neighbor calculation)\n",
        "                # Only proceed if Latitude and Longitude columns are present AND time conversion was successful\n",
        "                if time_conversion_successful and 'Latitude' in df_processed.columns and 'Longitude' in df_processed.columns:\n",
        "                    print(\"Converting lat/long to X/Y coordinates...\")\n",
        "                    ref_lat = df_processed['Latitude'].mean()\n",
        "                    ref_long = df_processed['Longitude'].mean()\n",
        "                    x_coords, y_coords = latlong_to_xy(df_processed['Latitude'], df_processed['Longitude'], ref_lat, ref_long)\n",
        "                    df_processed['Position X (m)'] = x_coords\n",
        "                    df_processed['Position Y (m)'] = y_coords\n",
        "                    print(\"Added 'Position X (m)' and 'Position Y (m)' columns.\")\n",
        "                    position_conversion_successful = True\n",
        "                else:\n",
        "                    print(\"Skipping lat/long to X/Y conversion or neighbor calculation: Required 'Latitude' or 'Longitude' columns not found or time conversion failed.\")\n",
        "                    position_conversion_successful = False\n",
        "                    # Add placeholder columns if conversion is skipped\n",
        "                    df_processed['Position X (m)'] = 0.0\n",
        "                    df_processed['Position Y (m)'] = 0.0\n",
        "                    df_processed[f'Number of Neighbors (10m)'] = 0\n",
        "                    df_processed['Risk Label'] = -1 # Use a value outside 0/1\n",
        "\n",
        "\n",
        "                # 3. Calculate number of neighbors within 10m (needed for risk labeling)\n",
        "                # Only proceed if Position X, Position Y, Time (s), and Vehicle ID are present AND time/position conversion was successful\n",
        "                neighbor_count_col_name = f'Number of Neighbors (10m)'\n",
        "                if position_conversion_successful and all(col in df_processed.columns for col in ['Position X (m)', 'Position Y (m)', 'Time (s)', 'Vehicle ID']):\n",
        "                    print(f\"Calculating {neighbor_count_col_name}...\")\n",
        "                    neighbor_counts = calculate_neighbors_count(df_processed, distance_threshold=10) # Calculate neighbors within 10m\n",
        "                    df_processed[neighbor_count_col_name] = neighbor_counts # Add the calculated series\n",
        "                    print(f\"Added '{neighbor_count_col_name}' column.\")\n",
        "                    neighbor_calculation_successful = True\n",
        "                else:\n",
        "                    print(f\"Skipping {neighbor_count_col_name} calculation: Required position, time, or vehicle ID columns not found or conversions failed.\")\n",
        "                    neighbor_calculation_successful = False\n",
        "                    if neighbor_count_col_name not in df_processed.columns:\n",
        "                         df_processed[neighbor_count_col_name] = 0 # Add placeholder if calculation skipped\n",
        "                    df_processed['Risk Label'] = -1 # Use a value outside 0/1\n",
        "\n",
        "\n",
        "                # --- Apply Risk Labeling Rule ---\n",
        "                print(\"Applying risk labeling rule...\")\n",
        "                # Only proceed if Speed and the calculated neighbor count column exist AND neighbor calculation was successful\n",
        "                if neighbor_calculation_successful and 'Speed (m/s)' in df_processed.columns and neighbor_count_col_name in df_processed.columns:\n",
        "                    # Risk Label = 1 if Speed > 35 AND Number of Neighbors (10m) > 0, else 0\n",
        "                    df_processed['Risk Label'] = np.where(\n",
        "                        (df_processed['Speed (m/s)'] > 35) & (df_processed[neighbor_count_col_name] > 0),\n",
        "                        1, # Risky\n",
        "                        0  # Safe\n",
        "                    )\n",
        "                    print(\"Risk labeling complete.\")\n",
        "\n",
        "                    # Print counts of each risk label for this file\n",
        "                    risk_label_counts = df_processed['Risk Label'].value_counts()\n",
        "                    safe_count = risk_label_counts.get(0, 0)\n",
        "                    risky_count = risk_label_counts.get(1, 0)\n",
        "                    print(f\"Generated Risk Labels for {file_name}: {safe_count} safe (0) and {risky_count} risky (1) instances\")\n",
        "\n",
        "                else:\n",
        "                    print(\"Skipping risk labeling: Required 'Speed (m/s)' or neighbor count column not found or neighbor calculation failed.\")\n",
        "                    # Add placeholder column if labeling is skipped\n",
        "                    if 'Risk Label' not in df_processed.columns:\n",
        "                         df_processed['Risk Label'] = -1 # Use a value outside 0/1\n",
        "\n",
        "\n",
        "                # --- Add the new columns to the original DataFrame structure ---\n",
        "                # This step is crucial to add only the new columns ('Number of Neighbors (10m)' and 'Risk Label')\n",
        "                # to the original DataFrame structure, keeping all its original columns.\n",
        "                # We use the index to align the data correctly.\n",
        "                # Ensure the new columns exist in df_processed before trying to select them\n",
        "                new_cols_to_merge = []\n",
        "                if neighbor_count_col_name in df_processed.columns:\n",
        "                    new_cols_to_merge.append(neighbor_count_col_name)\n",
        "                if 'Risk Label' in df_processed.columns:\n",
        "                    new_cols_to_merge.append('Risk Label')\n",
        "\n",
        "                if new_cols_to_merge:\n",
        "                    new_columns_df = df_processed[new_cols_to_merge].copy()\n",
        "\n",
        "                    # Ensure the indices match before merging\n",
        "                    if not df.index.equals(new_columns_df.index):\n",
        "                         print(f\"Warning: Index mismatch between original and processed dataframes for {file_name}. Attempting reindex.\")\n",
        "                         new_columns_df = new_columns_df.reindex(df.index) # Reindex to match original\n",
        "\n",
        "                    # Add the new columns to the original DataFrame.\n",
        "                    # Use .get() to avoid KeyError if column already exists\n",
        "                    for col in new_cols_to_merge:\n",
        "                        if col not in df.columns:\n",
        "                             df[col] = new_columns_df[col]\n",
        "                        else:\n",
        "                             # If column exists, overwrite it (shouldn't happen in this logic unless rerun)\n",
        "                             df[col] = new_columns_df[col]\n",
        "                             print(f\"Warning: Overwriting existing column '{col}' in {file_name}.\")\n",
        "                else:\n",
        "                     print(\"No new columns were successfully generated to merge.\")\n",
        "\n",
        "\n",
        "                # --- Define the output file path ---\n",
        "                # Get the directory and the base filename without extension\n",
        "                dir_name = os.path.dirname(csv_file_path)\n",
        "                base_name = os.path.basename(csv_file_path)\n",
        "                name_without_ext, ext = os.path.splitext(base_name)\n",
        "\n",
        "                # Construct the new file path\n",
        "                output_file_name = f\"{name_without_ext}{OUTPUT_FILE_SUFFIX}\"\n",
        "                output_file_path = os.path.join(dir_name, output_file_name)\n",
        "\n",
        "                # --- Save the updated DataFrame to a NEW file ---\n",
        "                print(f\"Saving updated data to NEW file: {output_file_path}\")\n",
        "                # Use index=False to avoid writing the DataFrame index as a column\n",
        "                df.to_csv(output_file_path, index=False)\n",
        "                print(f\"Successfully saved updated data for {file_name} to {output_file_name}.\")\n",
        "\n",
        "            # --- End of File Processing Try Block ---\n",
        "            except Exception as e:\n",
        "                print(f\"\\nAn unexpected error occurred while processing {file_name}: {e}\")\n",
        "                traceback.print_exc() # Print full traceback for better debugging\n",
        "                print(f\"Skipping processing and saving for {file_name}.\")\n",
        "\n",
        "    # --- Main Except Blocks (for initial file finding) ---\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset directory or files not found at {os.path.abspath(KAGGLE_DATASETS_DIR)}\")\n",
        "        print(\"Please check the KAGGLE_DATASETS_DIR and KAGGLE_FILE_PATTERN variables.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred during initial file finding: {e}\")\n",
        "        traceback.print_exc() # Print full traceback for better debugging\n",
        "        print(\"\\nPlease review the error message and traceback for details.\")\n",
        "    finally:\n",
        "        print(\"\\n--- Script Execution Finished ---\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKg6E8GvVWxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Function to calculate coordinates in meter\n",
        "\n",
        "Purpose:\n",
        "Convert GPS coordinates to local Cartesian (X/Y) coordinates in meters for distance calculations.\n",
        "Key Components:\n",
        "\n",
        "Equirectangular Projection: Simplifies Earth's curvature for small areas.\n",
        "\n",
        "Reference Point: Uses mean lat/long as (0,0) if not provided.\n",
        "\n",
        "Earth Radius: Average value (R = 6371000 m) for approximation.\n",
        "\n",
        "Equations:\n",
        "\n",
        "X = R * cos(ref_lat) * (long - ref_long) (East-West)\n",
        "\n",
        "Y = R * (lat - ref_lat) (North-South)\n",
        "\n"
      ],
      "metadata": {
        "id": "0Z59HIdDcboq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions ---\n",
        "def latlong_to_xy(lat, long, ref_lat=None, ref_long=None):\n",
        "    \"\"\"\n",
        "    Convert latitude and longitude to X/Y coordinates in meters\n",
        "    using a reference point as origin (0,0). Uses equirectangular projection\n",
        "    for simplicity, which is suitable for small areas.\n",
        "\n",
        "    Args:\n",
        "        lat (pd.Series): Series of latitude values.\n",
        "        long (pd.Series): Series of longitude values.\n",
        "        ref_lat (float, optional): Reference latitude for the origin. Defaults to the mean latitude.\n",
        "        ref_long (float, optional): Reference longitude for the origin. Defaults to the mean longitude.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (x_coords, y_coords) in meters.\n",
        "    \"\"\"\n",
        "    if ref_lat is None:\n",
        "        ref_lat = lat.mean()  # Use mean latitude as reference\n",
        "    if ref_long is None:\n",
        "        ref_long = long.mean()  # Use mean longitude as reference\n",
        "\n",
        "    # Earth radius in meters (using a common average)\n",
        "    R = 6371000.0\n",
        "\n",
        "    # Convert degrees to radians\n",
        "    lat_rad = np.radians(lat)\n",
        "    long_rad = np.radians(long)\n",
        "    ref_lat_rad = np.radians(ref_lat)\n",
        "    ref_long_rad = np.radians(ref_long)\n",
        "\n",
        "    # Calculate X (East-West position) using equirectangular projection\n",
        "    x = R * np.cos(ref_lat_rad) * (long_rad - ref_long_rad)\n",
        "\n",
        "    # Calculate Y (North-South position) using equirectangular projection\n",
        "    y = R * (lat_rad - ref_lat_rad)\n",
        "\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "n7phRHFwYNoa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Number of Neighbors & Average Distance Function\n",
        "\n",
        "Purpose:\n",
        "Calculate the number of neighbors and average distance within a threshold for ML features.\n",
        "Key Components:\n",
        "\n",
        "KD-Tree: Efficient spatial indexing for fast neighbor searches.\n",
        "\n",
        "Grouping by Timestamp: Processes vehicles at the same time.\n",
        "\n",
        "Edge Handling: Skips timestamps with 0-1 vehicles, excludes self-neighbors.\n",
        "\n",
        "Output Metrics:\n",
        "\n",
        "Number of Neighbors: Count within distance_threshold.\n",
        "\n",
        "Average Distance: Mean distance to neighbors (or 2 * threshold if none)."
      ],
      "metadata": {
        "id": "sniacROYWSu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Calculate Number of Neighbors & Average Distance Function (Optimized with KD-Tree) ---\n",
        "# This is a general neighbor calculation for ML features, distinct from the 10m one for Risk Labeling\n",
        "def calculate_neighbor_metrics_for_ml(df, distance_threshold=100):\n",
        "    \"\"\"\n",
        "    Calculate the number of neighbors and average distance to neighbors for each vehicle\n",
        "    at each timestamp based on their positions using a KD-tree for efficiency.\n",
        "    This is for generating ML features, using a potentially different threshold than the risk label.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing vehicle data with 'Time (s)', 'Vehicle ID',\n",
        "                           'Position X (m)', and 'Position Y (m)' columns.\n",
        "        distance_threshold (float): The maximum distance in meters to consider a vehicle a neighbor\n",
        "                                    for the purpose of ML features.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The input DataFrame with 'Number of Neighbors' and 'Average Distance to Neighbors (m)' columns added.\n",
        "    \"\"\"\n",
        "    print(f\"Starting neighbor metrics calculation for ML features with distance threshold {distance_threshold}m...\")\n",
        "\n",
        "    # Ensure necessary columns exist\n",
        "    required_cols = ['Time (s)', 'Vehicle ID', 'Position X (m)', 'Position Y (m)']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        missing = [col for col in required_cols if col not in df.columns]\n",
        "        print(f\"Error: Required columns for ML neighbor calculation are missing: {missing}. Skipping calculation.\")\n",
        "        # Add placeholder columns to prevent downstream errors\n",
        "        if 'Number of Neighbors' not in df.columns:\n",
        "             df['Number of Neighbors'] = 0\n",
        "        if 'Average Distance to Neighbors (m)' not in df.columns:\n",
        "             df['Average Distance to Neighbors (m)'] = 0.0\n",
        "        return df # Return dataframe with placeholders\n",
        "\n",
        "    # Initialize new columns with default values\n",
        "    df['Number of Neighbors'] = 0\n",
        "    df['Average Distance to Neighbors (m)'] = 0.0\n",
        "\n",
        "    # Use a large value for default average distance if no neighbors\n",
        "    default_avg_distance = distance_threshold * 2\n",
        "\n",
        "    # Process data for each timestamp\n",
        "    timestamps = df['Time (s)'].unique()\n",
        "    print(f\"Processing {len(timestamps)} unique timestamps for ML neighbor metrics...\")\n",
        "\n",
        "    # Group by timestamp for efficient processing\n",
        "    grouped_by_time = df.groupby('Time (s)')\n",
        "\n",
        "    for i, (ts, vehicles_at_ts) in enumerate(grouped_by_time):\n",
        "        if (i + 1) % 100 == 0: # Print progress every 100 timestamps\n",
        "            print(f\"  Processing timestamp {i+1}/{len(timestamps)} (Time: {ts}s)\")\n",
        "\n",
        "        if len(vehicles_at_ts) <= 1:\n",
        "            # If 0 or 1 vehicle, no neighbors to calculate for this timestamp\n",
        "            continue\n",
        "\n",
        "        # Extract positions for KD-tree and get original dataframe indices\n",
        "        # Ensure positions are float type for KDTree\n",
        "        positions = vehicles_at_ts[['Position X (m)', 'Position Y (m)']].values.astype(float)\n",
        "        original_indices = vehicles_at_ts.index.tolist()\n",
        "\n",
        "        # Build KD-tree\n",
        "        tree = KDTree(positions)\n",
        "\n",
        "        # Query the KD-tree for neighbors within the distance threshold\n",
        "        # query_ball_point returns a list of lists, where each inner list contains the indices\n",
        "        # of neighbors for the corresponding point in the input positions array.\n",
        "        # The indices are relative to the positions array (0 to len(vehicles_at_ts)-1).\n",
        "        neighbor_indices_list = tree.query_ball_point(positions, distance_threshold)\n",
        "\n",
        "        # Calculate neighbor metrics for each vehicle at this timestamp\n",
        "        for i_local, original_df_index in enumerate(original_indices): # Iterate through the original indices\n",
        "            # Get the indices of neighbors for the i_local-th vehicle in the vehicles_at_ts subset\n",
        "            neighbors_relative_indices = neighbor_indices_list[i_local]\n",
        "\n",
        "            # Exclude the vehicle itself from its neighbors list\n",
        "            # The query_ball_point includes the point itself, so we need to remove index i_local\n",
        "            valid_neighbors_relative_indices = [idx for idx in neighbors_relative_indices if idx != i_local]\n",
        "\n",
        "            numNeighbors = len(valid_neighbors_relative_indices)\n",
        "            avgDistanceToNeighbors = 0.0 # Initialize average distance\n",
        "\n",
        "            if numNeighbors > 0:\n",
        "                # Get the positions of the actual neighbors using relative indices\n",
        "                neighbor_positions = positions[valid_neighbors_relative_indices]\n",
        "\n",
        "                # Get the position of the current vehicle\n",
        "                current_vehicle_pos = positions[i_local]\n",
        "\n",
        "                # Calculate distances to these neighbors using numpy.linalg.norm\n",
        "                distances_to_neighbors = la.norm(neighbor_positions - current_vehicle_pos, axis=1)\n",
        "                avgDistanceToNeighbors = np.mean(distances_to_neighbors)\n",
        "            else:\n",
        "                avgDistanceToNeighbors = default_avg_distance # Assign default if no neighbors\n",
        "\n",
        "            # Update the original dataframe using the original index\n",
        "            df.at[original_df_index, 'Number of Neighbors'] = numNeighbors\n",
        "            df.at[original_df_index, 'Average Distance to Neighbors (m)'] = avgDistanceToNeighbors\n",
        "\n",
        "\n",
        "    print(\"ML neighbor metrics calculation complete.\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "NQd0npLNWhub"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Classes and Function to create Test and Train Data and DataLoader\n",
        "\n",
        "Purpose:\n",
        "Convert preprocessed data into PyTorch-compatible datasets.\n",
        "Key Components:\n",
        "\n",
        "Tensor Conversion: Converts NumPy arrays to PyTorch tensors.\n",
        "\n",
        "Feature-Label Split:\n",
        "\n",
        "Features: Vehicle ID, position, speed, acceleration, neighbor metrics.\n",
        "\n",
        "Labels: Risk Label (0 = safe, 1 = risky).\n",
        "\n"
      ],
      "metadata": {
        "id": "71qoCQ_EcmrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- Dataset Class ---\n",
        "class V2VDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for V2V log data.\"\"\"\n",
        "    def __init__(self, features, labels):\n",
        "        # Convert numpy arrays to PyTorch tensors\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        # Labels are now discrete class indices (0 or 1), use dtype as long for classification\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "-jiNMg0PYUmM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Preprocessing\n",
        "\n",
        "Purpose:\n",
        "Load CSV files, engineer features, and prepare train/test splits.\n",
        "Key Steps:\n",
        "\n",
        "File Loading:\n",
        "\n",
        "Combines multiple CSV files into a single DataFrame.\n",
        "\n",
        "Validates required columns (e.g., Risk Label).\n",
        "\n",
        "Timestamp Conversion:\n",
        "\n",
        "Converts datetime to numeric (seconds since epoch).\n",
        "\n",
        "Position Calculation:\n",
        "\n",
        "Uses latlong_to_xy to derive Position X/Y (m).\n",
        "\n",
        "Acceleration Calculation:\n",
        "\n",
        "Computes acceleration from speed differences over time.\n",
        "\n",
        "Neighbor Metrics:\n",
        "\n",
        "Calls calculate_neighbor_metrics_for_ml for ML features.\n",
        "\n",
        "Feature Scaling:\n",
        "\n",
        "Standardizes features using StandardScaler.\n",
        "\n",
        "Train/Test Split:\n",
        "\n",
        "80/20 stratified split to preserve class balance."
      ],
      "metadata": {
        "id": "NT8D4cgzWslO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "def load_and_preprocess_data(data_dir, file_pattern, column_mapping, neighbor_distance_threshold=100):\n",
        "    \"\"\"\n",
        "    Loads data from multiple CSV files, preprocesses it, and splits into train/test sets\n",
        "    for binary classification. Performs feature engineering within this function.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Directory containing the CSV files.\n",
        "        file_pattern (str): Pattern to match CSV files (e.e.g., '*.csv').\n",
        "        column_mapping (dict): Mapping from original CSV column names to desired names.\n",
        "        neighbor_distance_threshold (float): Distance threshold for calculating neighbor metrics for ML features.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dataloader, test_dataloader, scaler, y_test, feature_names)\n",
        "               train_dataloader: DataLoader for the training set.\n",
        "               test_dataloader: DataLoader for the testing data.\n",
        "               scaler: The fitted StandardScaler object.\n",
        "               y_test: The true labels of the test set (for confusion matrix).\n",
        "               feature_names: List of names of the features used for training.\n",
        "               Returns (None, None, None, None, None) if data loading or processing fails.\n",
        "    \"\"\"\n",
        "    full_pattern = os.path.join(data_dir, file_pattern)\n",
        "    print(f\"Attempting to find and load CSV files from: {os.path.abspath(data_dir)} matching pattern '{file_pattern}'\")\n",
        "\n",
        "    csv_files = glob.glob(full_pattern)\n",
        "\n",
        "    if not csv_files:\n",
        "        print(f\"No CSV files found matching '{file_pattern}' in '{data_dir}'.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    all_dataframes = []\n",
        "    print(f\"Found {len(csv_files)} CSV files. Loading and combining...\")\n",
        "\n",
        "    for csv_file_path in csv_files:\n",
        "        file_name = os.path.basename(csv_file_path)\n",
        "        print(f\"Loading file: {file_name}\")\n",
        "        try:\n",
        "            df_single = pd.read_csv(csv_file_path)\n",
        "            all_dataframes.append(df_single)\n",
        "            print(f\"Loaded {len(df_single)} rows from {file_name}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {csv_file_path}: {e}. Skipping.\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    if not all_dataframes:\n",
        "        print(\"No data loaded from any of the files. Exiting.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "    print(f\"\\nCombined data from all files. Total rows: {len(combined_df)}\")\n",
        "    print(f\"Original columns in combined data: {combined_df.columns.tolist()}\")\n",
        "\n",
        "\n",
        "    # --- Select and Rename necessary columns based on mapping ---\n",
        "    cols_to_select = list(column_mapping.keys())\n",
        "\n",
        "    missing_cols_in_source = [col for col in cols_to_select if col not in combined_df.columns]\n",
        "    if missing_cols_in_source:\n",
        "         print(f\"Error: The following columns specified in COLUMN_MAPPING are NOT found in the combined dataset: {missing_cols_in_source}\")\n",
        "         print(\"Please verify the column names in the CSV files and update COLUMN_MAPPING.\")\n",
        "         return None, None, None, None, None\n",
        "\n",
        "    df_processed = combined_df[cols_to_select].copy()\n",
        "    df_processed.rename(columns=column_mapping, inplace=True)\n",
        "    print(f\"Columns after selecting and renaming: {df_processed.columns.tolist()}\")\n",
        "\n",
        "    # --- Data Preprocessing ---\n",
        "    # 1. Convert timestamp to numeric\n",
        "    print(\"Processing timestamp...\")\n",
        "    try:\n",
        "        df_processed['Time (s)'] = pd.to_datetime(df_processed['Time (s)'])\n",
        "        if df_processed['Time (s)'].dt.tz is not None:\n",
        "            df_processed['Time (s)'] = df_processed['Time (s)'].dt.tz_localize(None)\n",
        "        df_processed['Time (s)'] = df_processed['Time (s)'].astype(np.int64) // 10**9\n",
        "        print(\"Converted 'Time (s)' to seconds since epoch (numeric).\")\n",
        "        time_conversion_successful = True\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting 'Time (s)' to numeric: {e}.\")\n",
        "        traceback.print_exc()\n",
        "        print(\"Skipping acceleration and neighbor metrics calculation due to time conversion failure.\")\n",
        "        time_conversion_successful = False\n",
        "        # Add placeholder columns if conversion fails\n",
        "        if 'Position X (m)' not in df_processed.columns: df_processed['Position X (m)'] = 0.0\n",
        "        if 'Position Y (m)' not in df_processed.columns: df_processed['Position Y (m)'] = 0.0\n",
        "        if 'Calculated Acceleration (m/s^2)' not in df_processed.columns: df_processed['Calculated Acceleration (m/s^2)'] = 0.0\n",
        "        if 'Number of Neighbors' not in df_processed.columns: df_processed['Number of Neighbors'] = 0\n",
        "        if 'Average Distance to Neighbors (m)' not in df_processed.columns: df_processed['Average Distance to Neighbors (m)'] = 0.0\n",
        "\n",
        "\n",
        "    # 2. Convert latitude/longitude to X/Y coordinates\n",
        "    if time_conversion_successful and 'Latitude' in df_processed.columns and 'Longitude' in df_processed.columns:\n",
        "        print(\"Converting lat/long to X/Y coordinates...\")\n",
        "        ref_lat = df_processed['Latitude'].mean()\n",
        "        ref_long = df_processed['Longitude'].mean()\n",
        "        x_coords, y_coords = latlong_to_xy(df_processed['Latitude'], df_processed['Longitude'], ref_lat, ref_long)\n",
        "        df_processed['Position X (m)'] = x_coords\n",
        "        df_processed['Position Y (m)'] = y_coords # Corrected typo here\n",
        "        print(\"Added 'Position X (m)' and 'Position Y (m)' columns.\")\n",
        "        position_conversion_successful = True\n",
        "    else:\n",
        "        print(\"Skipping lat/long to X/Y conversion: Required 'Latitude' or 'Longitude' columns not found or time conversion failed.\")\n",
        "        position_conversion_successful = False\n",
        "        if 'Position X (m)' not in df_processed.columns: df_processed['Position X (m)'] = 0.0\n",
        "        if 'Position Y (m)' not in df_processed.columns: df_processed['Position Y (m)'] = 0.0\n",
        "        if 'Calculated Acceleration (m/s^2)' not in df_processed.columns: df_processed['Calculated Acceleration (m/s^2)'] = 0.0\n",
        "        if 'Number of Neighbors' not in df_processed.columns: df_processed['Number of Neighbors'] = 0\n",
        "        if 'Average Distance to Neighbors (m)' not in df_processed.columns: df_processed['Average Distance to Neighbors (m)'] = 0.0\n",
        "\n",
        "\n",
        "    # 3. Calculate acceleration from speed\n",
        "    if time_conversion_successful and 'Speed (m/s)' in df_processed.columns and 'Time (s)' in df_processed.columns and 'Vehicle ID' in df_processed.columns:\n",
        "         print(\"Calculating acceleration...\")\n",
        "         df_sorted = df_processed.sort_values(by=['Vehicle ID', 'Time (s)']).copy()\n",
        "         df_sorted['Delta_Time'] = df_sorted.groupby('Vehicle ID')['Time (s)'].diff()\n",
        "         df_sorted['Delta_Speed'] = df_sorted.groupby('Vehicle ID')['Speed (m/s)'].diff()\n",
        "         df_sorted['Calculated Acceleration (m/s^2)'] = df_sorted.apply(\n",
        "             lambda row: row['Delta_Speed'] / row['Delta_Time'] if pd.notna(row['Delta_Time']) and row['Delta_Time'] > 1e-9 else 0, axis=1\n",
        "         )\n",
        "         df_sorted.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "         df_sorted['Calculated Acceleration (m/s^2)'].fillna(0, inplace=True)\n",
        "         df_processed['Calculated Acceleration (m/s^2)'] = df_sorted['Calculated Acceleration (m/s^2)']\n",
        "         print(\"Acceleration calculation complete.\")\n",
        "    else:\n",
        "         print(\"Skipping acceleration calculation: Required columns not found or time conversion failed.\")\n",
        "         if 'Calculated Acceleration (m/s^2)' not in df_processed.columns: df_processed['Calculated Acceleration (m/s^2)'] = 0.0\n",
        "\n",
        "\n",
        "    # 4. Calculate general neighbor metrics for ML features\n",
        "    if position_conversion_successful and all(col in df_processed.columns for col in ['Position X (m)', 'Position Y (m)', 'Time (s)', 'Vehicle ID']):\n",
        "        df_processed = calculate_neighbor_metrics_for_ml(df_processed, neighbor_distance_threshold)\n",
        "        print(\"Added 'Number of Neighbors' and 'Average Distance to Neighbors (m)' columns for ML features.\")\n",
        "    else:\n",
        "        print(\"Skipping ML neighbor metrics calculation: Required position, time, or vehicle ID columns not found or conversions failed.\")\n",
        "        if 'Number of Neighbors' not in df_processed.columns: df_processed['Number of Neighbors'] = 0\n",
        "        if 'Average Distance to Neighbors (m)' not in df_processed.columns: df_processed['Average Distance to Neighbors (m)'] = 0.0\n",
        "\n",
        "\n",
        "    # --- Select Final Features and Labels for ML ---\n",
        "    # These are the columns that will be used as input to the ML model\n",
        "    ml_feature_columns = [\n",
        "        'Vehicle ID', 'Time (s)', 'Position X (m)', 'Position Y (m)',\n",
        "        'Speed (m/s)', 'Calculated Acceleration (m/s^2)',\n",
        "        'Number of Neighbors', 'Average Distance to Neighbors (m)'\n",
        "    ]\n",
        "    ml_label_column = 'Risk Label' # <<< Use the Risk Label column\n",
        "\n",
        "    # Check if the final required columns for ML are present after all processing\n",
        "    missing_ml_features = [col for col in ml_feature_columns if col not in df_processed.columns]\n",
        "    if missing_ml_features:\n",
        "        print(f\"Error: Missing required ML feature columns after processing: {missing_ml_features}\")\n",
        "        return None, None, None, None, None\n",
        "    if ml_label_column not in df_processed.columns:\n",
        "        print(f\"Error: Missing ML label column '{ml_label_column}' after processing.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    features = df_processed[ml_feature_columns].values\n",
        "    labels = df_processed[ml_label_column].values # Use the Risk Label as target\n",
        "\n",
        "    # --- Filter Labels for Binary Classification (0 or 1) ---\n",
        "    # The Risk Label should already be 0 or 1, but this is a safeguard\n",
        "    valid_labels_mask = np.isin(labels, [0, 1])\n",
        "    if not np.all(valid_labels_mask):\n",
        "        print(f\"Warning: Filtering out {len(labels) - np.sum(valid_labels_mask)} rows with labels outside of [0, 1] for binary classification.\")\n",
        "        features = features[valid_labels_mask]\n",
        "        labels = labels[valid_labels_mask]\n",
        "        print(f\"Remaining data points after filtering: {len(labels)}\")\n",
        "\n",
        "    if len(labels) < 2 or len(np.unique(labels)) < 2:\n",
        "        print(f\"Insufficient data or only one class ({np.unique(labels)}) remaining after filtering ({len(labels)} data points). Cannot train/evaluate.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "\n",
        "    # --- Handle Missing Values (NaNs) ---\n",
        "    nan_count = np.isnan(features).sum()\n",
        "    if nan_count > 0:\n",
        "        print(f\"Warning: Found {nan_count} NaN values in features after processing. Filling NaNs with 0.\")\n",
        "        features = np.nan_to_num(features, nan=0.0)\n",
        "\n",
        "    # --- Feature Scaling ---\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    # --- Split Data ---\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            features_scaled, labels, test_size=0.2, random_state=42, stratify=labels # Stratify helps maintain label distribution\n",
        "        )\n",
        "    except ValueError as ve:\n",
        "        print(f\"Error splitting data: {ve}. This might happen if a class has too few samples after filtering.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "\n",
        "    # --- Create PyTorch Datasets and Dataloaders ---\n",
        "    train_dataset = V2VDataset(X_train, y_train)\n",
        "    test_dataset = V2VDataset(X_test, y_test)\n",
        "\n",
        "    # Define batch size for training\n",
        "    batch_size = 64 # You can adjust this\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # No need to shuffle test data\n",
        "\n",
        "    print(\"Data loading and preprocessing complete.\")\n",
        "\n",
        "    # Return feature names for plotting feature importance\n",
        "    return train_dataloader, test_dataloader, scaler, y_test, ml_feature_columns # Added feature names to return\n"
      ],
      "metadata": {
        "id": "Ra0_7sGRWq5K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture for both Client and Server\n",
        "\n",
        "Purpose:\n",
        "First part of the split learning model (privacy-preserving).\n",
        "Structure:\n",
        "\n",
        "Input Layer: 8 features (e.g., position, speed).\n",
        "\n",
        "Hidden Layer: 64 neurons with ReLU activation.\n",
        "\n",
        "Output: Activations sent to the server.\n",
        "\n",
        "Purpose:\n",
        "Second part of the split learning model (centralized computation).\n",
        "Structure:\n",
        "\n",
        "Hidden Layer: 32 neurons with ReLU.\n",
        "\n",
        "Output Layer: 2 logits (binary classification).\n",
        "\n",
        "Loss: Cross-entropy loss (no softmax – handled by PyTorch).\n",
        "\n"
      ],
      "metadata": {
        "id": "fnZThIzlcyhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Model Architectures ---\n",
        "# client_model.py (Simulated)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "class ClientModel(nn.Module):\n",
        "    def __init__(self, input_dim=8, client_output_dim=64):\n",
        "        \"\"\"\n",
        "        Client-side model (Input layer + 1 hidden layer).\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimension of the input feature vector (8 in your case).\n",
        "            client_output_dim (int): Dimension of the output activations from the client.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # First Linear layer\n",
        "        self.fc1 = nn.Linear(input_dim, client_output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the client model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input feature tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output activations after ReLU.\n",
        "        \"\"\"\n",
        "        # Apply Linear layer and then ReLU activation\n",
        "        activations = F.relu(self.fc1(x))\n",
        "        return activations\n",
        "\n",
        "# server_model.py (Simulated)\n",
        "class ServerModel(nn.Module):\n",
        "    def __init__(self, server_input_dim=64, hidden_dim=32, output_dim=2):\n",
        "        \"\"\"\n",
        "        Server-side model (Remaining hidden layers + output layer).\n",
        "        output_dim=2 is correct for binary classification with CrossEntropyLoss.\n",
        "\n",
        "        Args:\n",
        "            server_input_dim (int): Dimension of the input activations from the client.\n",
        "            hidden_dim (int): Dimension of the server's hidden layer.\n",
        "            output_dim (int): Dimension of the final output (2 for binary classification).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Second Linear layer\n",
        "        self.fc2 = nn.Linear(server_input_dim, hidden_dim)\n",
        "        # Output Linear layer (outputs logits for 2 classes)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the server model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input activations from the client.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Final output logits for each class.\n",
        "        \"\"\"\n",
        "        # Apply second Linear layer and ReLU\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Apply output Linear layer (no activation here, CrossEntropyLoss expects logits)\n",
        "        output = self.out(x)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "tx6AVD-SYZu0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function\n",
        "\n",
        "Purpose:\n",
        "Simulate split learning training while protecting raw data.\n",
        "Key Steps:\n",
        "\n",
        "Forward Pass:\n",
        "\n",
        "Client computes activations (client_model).\n",
        "\n",
        "Server computes logits (server_model).\n",
        "\n",
        "Loss Calculation:\n",
        "Cross-entropy loss between logits and labels.\n",
        "\n",
        "Backward Pass:\n",
        "\n",
        "Server calculates gradients and sends them to the client.\n",
        "\n",
        "Client updates its model without exposing raw data.\n",
        "\n",
        "Optimization:\n",
        "Separate Adam optimizers for client/server.\n",
        "\n",
        "Evaluation:\n",
        "Tracks training/test loss, accuracy, and predictions."
      ],
      "metadata": {
        "id": "3KmBV4mic94M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Training Function ---\n",
        "def train_split_learning(client_model, server_model, train_dataloader, test_dataloader, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Simulates the Split Learning training process for binary classification.\n",
        "\n",
        "    Args:\n",
        "        client_model (nn.Module): The client-side PyTorch model.\n",
        "        server_model (nn.Module): The server-side PyTorch model.\n",
        "        train_dataloader (DataLoader): DataLoader for the training data.\n",
        "        test_dataloader (DataLoader): DataLoader for the testing data.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (training_losses, test_losses, epochs_list, all_test_labels, all_test_predictions)\n",
        "               training_losses: List of training losses per epoch.\n",
        "               test_losses: List of test losses per epoch.\n",
        "               epochs_list: List of epoch numbers.\n",
        "               all_test_labels: The true labels of the test set.\n",
        "               all_test_predictions: The model's predictions on the test set.\n",
        "    \"\"\"\n",
        "    # Define optimizers for client and server models\n",
        "    client_optimizer = optim.Adam(client_model.parameters(), lr=0.001)\n",
        "    server_optimizer = optim.Adam(server_model.parameters(), lr=0.001)\n",
        "\n",
        "    # Define the loss function (Cross-Entropy Loss for binary classification)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Move models to the appropriate device (CPU or GPU if available)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    client_model.to(device)\n",
        "    server_model.to(device)\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Lists to store loss values for plotting\n",
        "    training_losses = []\n",
        "    test_losses = []\n",
        "    epochs_list = []\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        client_model.train() # Set client model to training mode\n",
        "        server_model.train() # Set server model to training mode\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "            # Move data to the device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # --- Split Learning Step 1: Client Forward Pass ---\n",
        "            # Client computes activations\n",
        "            client_optimizer.zero_grad() # Zero client gradients before forward pass\n",
        "            client_activations = client_model(inputs)\n",
        "\n",
        "            # --- Simulate sending activations to server ---\n",
        "            # Detach activations to cut the graph for the client's part\n",
        "            detached_activations = client_activations.detach()\n",
        "\n",
        "            # --- Simulate receiving activations on server and reattaching for server's graph ---\n",
        "            # Clone the detached activations and set requires_grad=True for the server's backward pass\n",
        "            server_input = detached_activations.clone().requires_grad_(True)\n",
        "\n",
        "\n",
        "            # --- Split Learning Step 2: Server Forward Pass and Loss Calculation ---\n",
        "            # Server computes output logits\n",
        "            server_optimizer.zero_grad() # Zero server gradients before forward pass\n",
        "            server_outputs = server_model(server_input)\n",
        "\n",
        "            # Calculate loss (CrossEntropyLoss expects logits and target class indices)\n",
        "            loss = criterion(server_outputs, labels)\n",
        "\n",
        "\n",
        "            # --- Split Learning Step 3: Server Backward Pass ---\n",
        "            # Server performs backward pass to calculate gradients for server model and the server_input (activations)\n",
        "            loss.backward() # Compute gradients\n",
        "\n",
        "            # --- Simulate sending gradients back to client ---\n",
        "            # Server gets gradients for the cut layer (server_input)\n",
        "            gradients_to_client = server_input.grad\n",
        "\n",
        "            # --- Split Learning Step 4: Client Backward Pass ---\n",
        "            # Client receives gradients and performs backward pass starting from its original activations\n",
        "            # The gradients from the server are applied to the corresponding activations on the client side\n",
        "            client_activations.backward(gradients_to_client)\n",
        "\n",
        "            # --- Split Learning Step 5: Optimizer Steps ---\n",
        "            # Update model weights using the calculated gradients\n",
        "            client_optimizer.step()\n",
        "            server_optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Print loss periodically\n",
        "            if (i + 1) % 100 == 0: # Print every 100 batches\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Calculate average training loss for the epoch\n",
        "        avg_train_loss = running_loss / len(train_dataloader)\n",
        "        training_losses.append(avg_train_loss)\n",
        "        epochs_list.append(epoch + 1) # Store epoch number\n",
        "\n",
        "\n",
        "        # --- Evaluation after each epoch (for monitoring during training) ---\n",
        "        client_model.eval() # Set client model to evaluation mode\n",
        "        server_model.eval() # Set server model to evaluation mode\n",
        "        test_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        # Do not collect all test labels/predictions here to save memory if test set is large\n",
        "        # Collection for final confusion matrix will happen after the loop\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient calculation during evaluation\n",
        "            for inputs, labels in test_dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Client forward pass\n",
        "                client_activations = client_model(inputs)\n",
        "\n",
        "                # Server forward pass (no need to detach/reattach in eval mode)\n",
        "                server_outputs = server_model(client_activations)\n",
        "\n",
        "                # Calculate loss\n",
        "                test_loss += criterion(server_outputs, labels).item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                _, predicted = torch.max(server_outputs.data, 1)\n",
        "                total_predictions += labels.size(0)\n",
        "                correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "        # Calculate average test loss for the epoch\n",
        "        avg_test_loss = test_loss / len(test_dataloader)\n",
        "        test_losses.append(avg_test_loss)\n",
        "\n",
        "        accuracy = 100 * correct_predictions / total_predictions\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Test Loss (CrossEntropy): {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    print(\"Split Learning training finished.\")\n",
        "\n",
        "    # --- Collect all test labels and predictions AFTER training loop for final evaluation ---\n",
        "    client_model.eval()\n",
        "    server_model.eval()\n",
        "    all_test_labels = []\n",
        "    all_test_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            client_activations = client_model(inputs)\n",
        "            server_outputs = server_model(client_activations)\n",
        "            _, predicted = torch.max(server_outputs.data, 1)\n",
        "            all_test_labels.extend(labels.cpu().numpy())\n",
        "            all_test_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "\n",
        "    # Return collected data for plotting and evaluation\n",
        "    return training_losses, test_losses, epochs_list, all_test_labels, all_test_predictions, client_model # Added client_model to return\n"
      ],
      "metadata": {
        "id": "UKbIL_cOYewe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function to train the Model\n",
        "\n",
        "Purpose:\n",
        "Orchestrate end-to-end training.\n",
        "Key Steps:\n",
        "\n",
        "Configuration:\n",
        "\n",
        "Paths, column mappings, hyperparameters.\n",
        "\n",
        "Data Loading:\n",
        "Calls load_and_preprocess_data.\n",
        "\n",
        "Model Initialization:\n",
        "Client/server models moved to GPU if available.\n",
        "\n",
        "Training:\n",
        "Executes train_split_learning.\n",
        "\n",
        "Output:\n",
        "Saves losses, predictions, and models for evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "cRntWxzidByt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcWbGNCy3ysB",
        "outputId": "85e9d689-e1d5-4e06-d89a-c6bff265fa3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting V2V Split Learning Training (Part 1) ---\n",
            "Attempting to find and load CSV files from: /content/drive/My Drive/Lokm/simulation_results/Dataset matching pattern 'vehicular_dataset_*.csv'\n",
            "Found 1 CSV files. Loading and combining...\n",
            "Loading file: vehicular_dataset_2025-01-07.csv\n",
            "Loaded 4320000 rows from vehicular_dataset_2025-01-07.csv.\n",
            "\n",
            "Combined data from all files. Total rows: 4320000\n",
            "Original columns in combined data: ['VehicleID', 'Timestamp', 'Day', 'Hour', 'Minute', 'Second', 'Latitude', 'Longitude', 'Speed', 'Direction', 'StartingPointLatitude', 'StartingPointLongitude', 'DestinationLatitude', 'DestinationLongitude', 'CPU_Available', 'Memory_Available', 'BatteryLevel', 'TaskType', 'TaskSize', 'TaskPriority', 'NetworkLatency', 'SignalStrength', 'TrafficDensity', 'WeatherCondition', 'RoadCondition', 'VehicleType', 'VehicleAge', 'EngineTemperature', 'FuelLevel', 'TirePressure', 'BrakeFluidLevel', 'CoolantLevel', 'OilLevel', 'WiperFluidLevel', 'HeadlightStatus', 'BrakeLightStatus', 'TurnSignalStatus', 'HazardLightStatus', 'ABSStatus', 'AirbagStatus', 'GPSStatus', 'WiFiStatus', 'BluetoothStatus', 'CellularStatus', 'RadarStatus', 'LidarStatus', 'CameraStatus', 'IMUStatus', 'Odometer', 'TaskOffloaded', 'Number of Neighbors (10m)', 'Risk Label']\n",
            "Columns after selecting and renaming: ['Vehicle ID', 'Time (s)', 'Latitude', 'Longitude', 'Speed (m/s)', 'Risk Label']\n",
            "Processing timestamp...\n",
            "Converted 'Time (s)' to seconds since epoch (numeric).\n",
            "Converting lat/long to X/Y coordinates...\n",
            "Added 'Position X (m)' and 'Position Y (m)' columns.\n",
            "Calculating acceleration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-75d0f277e3b8>:121: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_sorted['Calculated Acceleration (m/s^2)'].fillna(0, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [1/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [1/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [1/10], Training Loss: 0.0005, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [2/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [2/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [2/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [3/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [3/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [3/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [4/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [4/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [4/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [5/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [5/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [5/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [6/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [6/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [6/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [7/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [7/10], Step [53900/54000], Loss: 0.0854\n",
            "Epoch [7/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [7/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [8/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [8/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [8/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [9/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [9/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [9/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Epoch [10/10], Step [100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [1900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [2900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [3900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [4900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [5900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [6900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [7900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [8900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [9900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [10900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [11900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [12900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [13900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [14900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [15900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [16900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [17900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [18900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [19900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [20900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [21900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [22900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [23900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [24900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [25900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [26900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [27900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [28900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [29900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [30900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [31900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [32900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [33900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [34900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [35900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [36900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [37900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [38900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [39900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [40900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [41900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [42900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [43900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [44900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [45900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [46900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [47900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [48900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [49900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [50900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [51900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [52900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53100/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53200/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53300/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53400/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53500/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53600/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53700/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53800/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [53900/54000], Loss: 0.0000\n",
            "Epoch [10/10], Step [54000/54000], Loss: 0.0000\n",
            "Epoch [10/10], Training Loss: 0.0000, Test Loss (CrossEntropy): 0.0000, Test Accuracy: 100.00%\n",
            "Split Learning training finished.\n",
            "\n",
            "--- Part 1: Training Completed ---\n",
            "Training losses, test losses, epoch list, test labels, predictions, and trained client model are stored in variables.\n",
            "Proceed to Part 2 for visualization.\n"
          ]
        }
      ],
      "source": [
        "# --- Part 1: ML Training Setup and Execution ---\n",
        "\n",
        "# --- All Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler # Recommended for scaling features\n",
        "\n",
        "# Import only modules needed for training setup in Part 1\n",
        "# Plotting imports will be in Part 2\n",
        "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, classification_report\n",
        "# from sklearn.manifold import TSNE\n",
        "# from matplotlib.gridspec import GridSpec\n",
        "# import matplotlib.colors as mcolors\n",
        "\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import json # To potentially save/load aggregated results\n",
        "import sys\n",
        "import math\n",
        "from scipy.spatial import KDTree # Import KDTree for efficient neighbor search\n",
        "import numpy.linalg as la # For calculating Euclidean distance efficiently\n",
        "import traceback # Import traceback for detailed error reporting\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# Directory containing the multiple Kaggle dataset files (assuming CSV format)\n",
        "# These are the files that should now contain the 'Risk Label' column\n",
        "KAGGLE_DATASETS_DIR = '/content/drive/My Drive/Lokm/simulation_results/Dataset' # <<< ADJUST THIS PATH\n",
        "\n",
        "# File pattern to search for within the directory\n",
        "# Assuming the files were processed by the labeling script to add 'Risk Label'\n",
        "KAGGLE_FILE_PATTERN = 'vehicular_dataset_*.csv' # Matches files created by the updated labeling script\n",
        "\n",
        "# Define a placeholder directory for plots, will be created if needed in Part 2\n",
        "PLOT_SAVE_DIR = 'training_plots'\n",
        "\n",
        "# --- Column Mapping (Map original CSV columns to names used in this script) ---\n",
        "# IMPORTANT: These keys MUST match the EXACT column names in your updated CSV files.\n",
        "# The values are the names used internally for processing and ML features.\n",
        "COLUMN_MAPPING = {\n",
        "    'VehicleID': 'Vehicle ID',\n",
        "    'Timestamp': 'Time (s)',\n",
        "    'Latitude': 'Latitude',\n",
        "    'Longitude': 'Longitude',\n",
        "    'Speed': 'Speed (m/s)',\n",
        "    # The 'Risk Label' column should now be present in your updated CSV files\n",
        "    'Risk Label': 'Risk Label', # <<< Ensure this matches the column name added by the update script\n",
        "    # The neighbor count added by the update script (e.g., 'Number of Neighbors (10m)')\n",
        "    # is NOT used directly as an ML feature here. We recalculate general neighbor metrics.\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Main Training Execution (Part 1) ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Starting V2V Split Learning Training (Part 1) ---\")\n",
        "\n",
        "    # Define the path to your dataset directory and file pattern\n",
        "    data_directory = KAGGLE_DATASETS_DIR\n",
        "    # Use the file pattern that matches the NEW files created by the update script\n",
        "    file_pattern = KAGGLE_FILE_PATTERN # Should be 'vehicular_dataset_*_with_risk_label_v2.csv'\n",
        "\n",
        "\n",
        "    # Load and preprocess the data (including feature engineering and splitting)\n",
        "    # These variables will hold the data and results needed for Part 2\n",
        "    train_dataloader, test_dataloader, scaler, y_test_original, feature_names = load_and_preprocess_data(\n",
        "        data_directory,\n",
        "        file_pattern,\n",
        "        COLUMN_MAPPING,\n",
        "        neighbor_distance_threshold=100 # Set the distance threshold for ML neighbor features\n",
        "    )\n",
        "\n",
        "    if train_dataloader is not None and test_dataloader is not None:\n",
        "        # Define model dimensions\n",
        "        # input_feature_dim is determined by the number of columns in ml_feature_columns\n",
        "        # We will get the actual dimension from the data after loading\n",
        "        input_feature_dim = len(feature_names) # Get input dimension from processed data\n",
        "        client_output_dim = 64 # As per your architecture\n",
        "        server_hidden_dim = 32 # As per your architecture\n",
        "        output_label_dim = 2 # 0 for safe, 1 for risky - correct for binary classification\n",
        "\n",
        "        # Instantiate the client and server models\n",
        "        # Define device early to pass to models\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        client_model = ClientModel(input_dim=input_feature_dim, client_output_dim=client_output_dim).to(device)\n",
        "        server_model = ServerModel(server_input_dim=client_output_dim, hidden_dim=server_hidden_dim, output_dim=output_label_dim).to(device)\n",
        "\n",
        "\n",
        "        print(\"\\nClient Model Architecture:\")\n",
        "        print(client_model)\n",
        "        print(\"\\nServer Model Architecture:\")\n",
        "        print(server_model)\n",
        "\n",
        "        # Start the Split Learning training process\n",
        "        # Store the results in variables that can be accessed in Part 2\n",
        "        # Note: In a true separate cell scenario, you'd need to ensure these variables\n",
        "        # are available in the global scope or passed explicitly.\n",
        "        training_losses, test_losses, epochs_list, all_test_labels, all_test_predictions, trained_client_model = train_split_learning(\n",
        "            client_model, server_model, train_dataloader, test_dataloader, num_epochs=10 # Set epochs to 10\n",
        "        )\n",
        "\n",
        "        print(\"\\n--- Part 1: Training Completed ---\")\n",
        "        print(\"Training losses, test losses, epoch list, test labels, predictions, and trained client model are stored in variables.\")\n",
        "        print(\"Proceed to Part 2 for visualization.\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"\\n--- Part 1: Data Loading or Preprocessing Failed ---\")\n",
        "        print(\"Skipping model training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChLXQeGc7Dhh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Learning curves for visualizatinon\n",
        "\n",
        "Purpose:\n",
        "Track model convergence and detect overfitting.\n",
        "Key Features:\n",
        "\n",
        "Dual Loss Lines: Training (blue) vs. Validation (red) loss.\n",
        "\n",
        "Moving Averages: Smoothed trends using adaptive window size.\n",
        "\n",
        "Generalization Gap: Gray shaded area between losses.\n",
        "\n",
        "Best Model Marker: Gold star at minimum validation loss.\n",
        "\n",
        "Final Loss Markers: Horizontal lines with exact values.\n",
        "\n",
        "Dynamic Scaling: Auto-adjusts axes to show annotations."
      ],
      "metadata": {
        "id": "zPMC84iSdHRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot detailed learning curves\n",
        "def plot_learning_curves(training_losses, test_losses, epochs_list, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves an enhanced visualization of training and validation loss curves.\n",
        "\n",
        "    Args:\n",
        "        training_losses: List of training losses per epoch\n",
        "        test_losses: List of test losses per epoch\n",
        "        epochs_list: List of epoch numbers\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Create a light background grid for better readability\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot training and test losses with different line styles and markers\n",
        "    plt.plot(epochs_list, training_losses, 'b-o', linewidth=2, markersize=8,\n",
        "             label='Training Loss', alpha=0.8)\n",
        "    plt.plot(epochs_list, test_losses, 'r-^', linewidth=2, markersize=8,\n",
        "             label='Validation Loss', alpha=0.8)\n",
        "\n",
        "    # Add trend lines (moving averages) for clearer visualization of patterns\n",
        "    if len(epochs_list) > 3:  # Only if we have enough epochs\n",
        "        window_size = max(2, len(epochs_list) // 5)  # Adaptive window size\n",
        "        train_ma = np.convolve(training_losses, np.ones(window_size)/window_size, mode='valid')\n",
        "        test_ma = np.convolve(test_losses, np.ones(window_size)/window_size, mode='valid')\n",
        "        # Adjust x-axis for moving average plots\n",
        "        plt.plot(epochs_list[window_size-1:], train_ma, 'b--', linewidth=1.5, alpha=0.5)\n",
        "        plt.plot(epochs_list[window_size-1:], test_ma, 'r--', linewidth=1.5, alpha=0.5)\n",
        "\n",
        "\n",
        "    # Highlight the epoch with minimum validation loss\n",
        "    if test_losses: # Ensure test_losses is not empty\n",
        "        min_loss_epoch = epochs_list[np.argmin(test_losses)]\n",
        "        min_loss_value = min(test_losses)\n",
        "        plt.scatter(min_loss_epoch, min_loss_value, s=200, c='gold',\n",
        "                    edgecolor='k', marker='*', label=f'Best Model (Epoch {min_loss_epoch})')\n",
        "\n",
        "        # Add annotations for the best model\n",
        "        plt.annotate(f'Min Loss: {min_loss_value:.4f}',\n",
        "                     xy=(min_loss_epoch, min_loss_value),\n",
        "                     xytext=(min_loss_epoch, min_loss_value*1.2),\n",
        "                     arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n",
        "                     fontsize=10, ha='center')\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Cross-Entropy Loss', fontsize=14, fontweight='bold') # Corrected line\n",
        "    plt.title('Training and Validation Loss Over Time', fontsize=16, fontweight='bold')\n",
        "    plt.legend(fontsize=12, loc='upper right')\n",
        "\n",
        "    # Add a shaded region showing the gap between training and validation loss (indicates overfitting)\n",
        "    plt.fill_between(epochs_list, training_losses, test_losses,\n",
        "                     color='gray', alpha=0.2, label='Generalization Gap')\n",
        "\n",
        "    # Add horizontal lines showing the final achieved losses (if lists are not empty)\n",
        "    if training_losses:\n",
        "        plt.axhline(y=training_losses[-1], color='b', linestyle='-.', alpha=0.3)\n",
        "        # Text annotations for final loss values\n",
        "        plt.text(epochs_list[-1] + 0.5, training_losses[-1],\n",
        "                 f'Final Training: {training_losses[-1]:.4f}',\n",
        "                 verticalalignment='center', color='blue')\n",
        "    if test_losses:\n",
        "        plt.axhline(y=test_losses[-1], color='r', linestyle='-.', alpha=0.3)\n",
        "        plt.text(epochs_list[-1] + 0.5, test_losses[-1],\n",
        "                 f'Final Validation: {test_losses[-1]:.4f}',\n",
        "                 verticalalignment='center', color='red')\n",
        "\n",
        "\n",
        "    # Adjust limits to show annotations clearly (only if lists are not empty)\n",
        "    if epochs_list and training_losses and test_losses:\n",
        "        plt.xlim(0, max(epochs_list) * 1.15)\n",
        "        plt.ylim(0, max(max(training_losses), max(test_losses)) * 1.3)\n",
        "    elif epochs_list: # If only epochs_list has data\n",
        "         plt.xlim(0, max(epochs_list) * 1.15)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'learning_curves.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "e9zerVI8Ymo2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Creates and saves an enhanced confusion matrix visualization with both absolute and normalized values.\n",
        "\n",
        "Purpose:\n",
        "Evaluate classification performance beyond accuracy.\n",
        "Key Features:\n",
        "\n",
        "Dual Visualization: Absolute counts + normalized percentages.\n",
        "\n",
        "Class Metrics: Precision/Recall/F1 displayed below.\n",
        "\n",
        "Error Handling: Skips plot for single-class data.\n",
        "\n",
        "Color Coding: Blue (counts) vs. Red-Yellow-Green (normalized)."
      ],
      "metadata": {
        "id": "BcK3m0HNyPaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_enhanced_confusion_matrix(y_true, y_pred, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves an enhanced confusion matrix visualization with both absolute\n",
        "    and normalized values.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels from test set\n",
        "        y_pred: Predicted labels from model\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    # Ensure there are enough data points and at least two classes in y_true\n",
        "    if len(y_true) < 2 or len(np.unique(y_true)) < 2:\n",
        "        print(\"Cannot plot confusion matrix: Insufficient data or only one class in test set.\")\n",
        "        plt.close() # Close the figure to prevent it from being displayed empty\n",
        "        return\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Handle potential division by zero if a row in cm sums to 0\n",
        "    cm_sum_axis1 = cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm_normalized = np.zeros_like(cm, dtype=float)\n",
        "    # Only divide if the sum is not zero\n",
        "    non_zero_rows = cm_sum_axis1.flatten() != 0\n",
        "    cm_normalized[non_zero_rows, :] = cm.astype('float')[non_zero_rows, :] / cm_sum_axis1[non_zero_rows, :]\n",
        "\n",
        "\n",
        "    # Create subplots for both absolute and normalized confusion matrices\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "    # Plot absolute confusion matrix\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax1)\n",
        "    ax1.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "    ax1.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "    ax1.set_title('Confusion Matrix (Absolute Counts)', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xticklabels(['Safe (0)', 'Risky (1)'])\n",
        "    ax1.set_yticklabels(['Safe (0)', 'Risky (1)'])\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='RdYlGn', cbar=True, ax=ax2)\n",
        "    ax2.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "    ax2.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xticklabels(['Safe (0)', 'Risky (1)'])\n",
        "    ax2.set_yticklabels(['Safe (0)', 'Risky (1)'])\n",
        "\n",
        "    # Calculate and display additional metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # Ensure both classes are present in true labels for classification_report to work fully\n",
        "    if len(np.unique(y_true)) >= 2:\n",
        "        report = classification_report(y_true, y_pred, output_dict=True)\n",
        "        # Ensure class 1 (Risky) exists in true labels before trying to access its metrics directly\n",
        "        if '1' in report:\n",
        "            precision = report['1']['precision']\n",
        "            recall = report['1']['recall']\n",
        "            f1 = report['1']['f1-score']\n",
        "            metrics_text = f\"Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\n\" \\\n",
        "                           f\"Recall: {recall:.4f}\\nF1 Score: {f1:.4f}\"\n",
        "        else:\n",
        "            # Handle case where there are no risky instances in the test set\n",
        "            metrics_text = f\"Accuracy: {accuracy:.4f}\\nPrecision: N/A\\nRecall: N/A\\nF1 Score: N/A\\n(No Risky instances in test set)\"\n",
        "    else:\n",
        "         metrics_text = f\"Accuracy: {accuracy:.4f}\\n(Insufficient data for full metrics)\"\n",
        "\n",
        "\n",
        "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "    plt.figtext(0.5, 0.01, metrics_text, fontsize=12, ha='center',\n",
        "                bbox=props)\n",
        "\n",
        "    plt.suptitle('Split Learning Model Performance - Confusion Matrices',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0.08, 1, 0.95])  # Adjust for the text box\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "exm5ALdFyS4R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caculate false positive and true positive to plot confusion matrix"
      ],
      "metadata": {
        "id": "ii6tBfCedNEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def false_positive_rate(y_true, y_pred):\n",
        "    \"\"\"Calculate the false positive rate.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Ensure class 0 exists in true labels before calculating\n",
        "    if 0 in np.unique(y_true):\n",
        "        false_positive = cm[0, 1]\n",
        "        true_negative = cm[0, 0]\n",
        "        return false_positive / (false_positive + true_negative) if (false_positive + true_negative) > 0 else 0\n",
        "    else:\n",
        "        return 0.0 # Cannot calculate FPR if no true negatives\n",
        "\n",
        "\n",
        "def true_positive_rate(y_true, y_pred):\n",
        "    \"\"\"Calculate the true positive rate (recall).\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Ensure class 1 exists in true labels before calculating\n",
        "    if 1 in np.unique(y_true):\n",
        "        true_positive = cm[1, 1]\n",
        "        false_negative = cm[1, 0]\n",
        "        return true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "    else:\n",
        "        return 0.0 # Cannot calculate TPR if no true positives\n",
        "\n"
      ],
      "metadata": {
        "id": "JXL05U5DYutU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates and saves a ROC curve visualization based on the model predictions.\n",
        "    This implementation handles binary class labels directly.\n",
        "\n",
        "Purpose:\n",
        "Assess trade-off between TPR (detection) and FPR (false alarms).\n",
        "Key Features:\n",
        "\n",
        "Dummy Probabilities: Converts class labels to binary probabilities.\n",
        "\n",
        "AUC Value: Area under curve quantifies overall performance.\n",
        "\n",
        "Current Model Marker: Red dot shows actual operating point.\n",
        "\n",
        "Baseline: Diagonal \"random guess\" line for reference."
      ],
      "metadata": {
        "id": "pXoxR6VByiaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_roc_curve(y_true, y_pred_class, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves a ROC curve visualization based on the model predictions.\n",
        "    This implementation handles binary class labels directly.\n",
        "\n",
        "    Args:\n",
        "        y_true: True binary labels (0 or 1)\n",
        "        y_pred_class: Predicted binary labels (0 or 1)\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    # Ensure both classes are present in y_true for roc_curve to work\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        print(\"Cannot plot ROC curve: Test set contains only one class.\")\n",
        "        plt.close()\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Convert class predictions to estimated probabilities for ROC curve\n",
        "    # Note: This is a simplification when only class predictions are available.\n",
        "    # For actual implementation, using model logits or predicted probabilities is preferred.\n",
        "    # Creating a dummy probability array based on class predictions.\n",
        "    y_pred_prob = np.zeros((len(y_pred_class), 2))\n",
        "    for i, pred in enumerate(y_pred_class):\n",
        "        if pred in [0, 1]: # Ensure predicted label is 0 or 1\n",
        "             y_pred_prob[i, pred] = 1.0\n",
        "        # If prediction is outside [0, 1], this row will have [0, 0] probabilities, which might affect AUC.\n",
        "        # Ideally, predictions should be strictly 0 or 1.\n",
        "\n",
        "\n",
        "    # Calculate ROC curve and ROC area for class 1 (Risky)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (area = {roc_auc:.3f})')\n",
        "\n",
        "    # Plot diagonal line (random classifier)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
        "             label='Random Classifier (AUC = 0.5)')\n",
        "\n",
        "    # Calculate point for current threshold (using the provided helper functions)\n",
        "    current_fpr = false_positive_rate(y_true, y_pred_class)\n",
        "    current_tpr = true_positive_rate(y_true, y_pred_class)\n",
        "\n",
        "    # Mark the current operating point\n",
        "    plt.scatter(current_fpr, current_tpr, color='red', s=100, zorder=10,\n",
        "                label=f'Current Model (FPR={current_fpr:.3f}, TPR={current_tpr:.3f})')\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=10)\n",
        "\n",
        "    # Add grid for readability\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "I78PES2ZykqS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functino to plot Precision Recall Curve\n",
        "\n",
        "Purpose:\n",
        "Evaluate performance under class imbalance.\n",
        "Key Features:\n",
        "\n",
        "F1 Contours: Dashed lines show F1-score thresholds.\n",
        "\n",
        "Baseline: Horizontal line for positive class prevalence.\n",
        "\n",
        "Current Model Marker: Red dot with exact metrics.\n",
        "\n",
        "Adaptive Annotations: Avoids label overlap on contours."
      ],
      "metadata": {
        "id": "WVFAoNgrdVPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_precision_recall_curve(y_true, y_pred_class, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves a Precision-Recall curve visualization.\n",
        "\n",
        "    Args:\n",
        "        y_true: True binary labels (0 or 1)\n",
        "        y_pred_class: Predicted binary labels (0 or 1)\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    # Ensure both classes are present in y_true for precision_recall_curve to work\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        print(\"Cannot plot Precision-Recall curve: Test set contains only one class.\")\n",
        "        plt.close()\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Convert class predictions to estimated probabilities\n",
        "    # Note: This is a simplification when only class predictions are available.\n",
        "    # For actual implementation, using model logits or predicted probabilities is preferred.\n",
        "    # Creating a dummy probability array based on class predictions.\n",
        "    y_pred_prob = np.zeros((len(y_pred_class), 2))\n",
        "    for i, pred in enumerate(y_pred_class):\n",
        "         if pred in [0, 1]: # Ensure predicted label is 0 or 1\n",
        "              y_pred_prob[i, pred] = 1.0\n",
        "         # If prediction is outside [0, 1], this row will have [0, 0] probabilities.\n",
        "\n",
        "\n",
        "    # Calculate precision-recall curve\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred_prob[:, 1])\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    # Plot precision-recall curve\n",
        "    plt.plot(recall, precision, color='blue', lw=2,\n",
        "             label=f'Precision-Recall curve (area = {pr_auc:.3f})')\n",
        "\n",
        "    # Calculate current precision and recall\n",
        "    cm = confusion_matrix(y_true, y_pred_class)\n",
        "    # Ensure class 1 exists in true labels for calculation\n",
        "    if 1 in np.unique(y_true):\n",
        "        current_precision = cm[1, 1] / (cm[1, 1] + cm[0, 1]) if (cm[1, 1] + cm[0, 1]) > 0 else 0\n",
        "        current_recall = cm[1, 1] / (cm[1, 1] + cm[1, 0]) if (cm[1, 1] + cm[1, 0]) > 0 else 0\n",
        "\n",
        "        # Mark the current operating point\n",
        "        plt.scatter(current_recall, current_precision, color='red', s=100, zorder=10,\n",
        "                    label=f'Current Model (Precision={current_precision:.3f}, Recall={current_recall:.3f})')\n",
        "\n",
        "    # Plot baseline\n",
        "    y_baseline = np.sum(y_true) / len(y_true)  # Proportion of positive class\n",
        "    plt.axhline(y=y_baseline, color='grey', linestyle='--',\n",
        "                 label=f'Baseline (No Skill): {y_baseline:.3f}')\n",
        "\n",
        "    # Calculate F1 contours for reference\n",
        "    f1_scores = np.linspace(0.1, 0.9, 9)\n",
        "    for f1 in f1_scores:\n",
        "        x = np.linspace(0.01, 1, 100)\n",
        "        # f1 = 2 * precision * recall / (precision + recall)\n",
        "        # Solve for precision in terms of recall and f1\n",
        "        y = (f1 * x) / (2 * x - f1)\n",
        "        valid_indices = (y >= 0) & (y <= 1)\n",
        "        plt.plot(x[valid_indices], y[valid_indices], color='green', alpha=0.2, linestyle=':')\n",
        "        # Add label for select contours\n",
        "        # Adjust annotation position to avoid overlap\n",
        "        if f1 in [0.3, 0.5, 0.7]:\n",
        "             midpoint = np.argmax(valid_indices & (x > 0.3) & (x < 0.7)) # Find a point in the middle range\n",
        "             if midpoint > 0:\n",
        "                 plt.annotate(f'F1={f1}', xy=(x[midpoint], y[midpoint]),\n",
        "                              xytext=(x[midpoint] + 0.05, y[midpoint]), # Offset text slightly\n",
        "                              textcoords='data',\n",
        "                              fontsize=8, alpha=0.6)\n",
        "\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('Precision', fontsize=12, fontweight='bold')\n",
        "    plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower left\", fontsize=10)\n",
        "\n",
        "    # Add grid for readability\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'precision_recall_curve.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "PDLRpGhMYxvx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creates and saves a visualization of feature importance based on the weights\n",
        "    of the first layer of the client model.\n",
        "\n",
        "  Purpose:\n",
        "Reveal which input features drive model decisions.\n",
        "Key Features:\n",
        "\n",
        "Weight Extraction: First layer weights from client model.\n",
        "\n",
        "Mean Absolute Impact: Horizontal bar chart of feature influence.\n",
        "\n",
        "Error Handling: Validates feature/model compatibility.\n",
        "\n",
        "Interpretation Guide: Text explains weight significance."
      ],
      "metadata": {
        "id": "cIfIZ6dbdd43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xwFIDDguywtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def analyze_feature_importance(client_model, feature_names, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves a visualization of feature importance based on the weights\n",
        "    of the first layer of the client model.\n",
        "\n",
        "    Args:\n",
        "        client_model: Trained client PyTorch model\n",
        "        feature_names: List of feature names\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    # Ensure client_model and feature_names are not None\n",
        "    if client_model is None or feature_names is None or not feature_names:\n",
        "        print(\"Cannot plot feature importance: Client model or feature names are not available.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Extract weights from the first layer of the client model\n",
        "    with torch.no_grad():\n",
        "        # Ensure weights are on CPU for numpy conversion\n",
        "        weights = client_model.fc1.weight.cpu().numpy()\n",
        "\n",
        "    # Calculate feature importance as the mean absolute weight per input feature\n",
        "    # Ensure the number of feature names matches the input dimension of the model\n",
        "    if len(feature_names) != weights.shape[1]:\n",
        "        print(f\"Warning: Number of feature names ({len(feature_names)}) does not match model input dimension ({weights.shape[1]}). Skipping feature importance plot.\")\n",
        "        plt.close() # Close the figure to prevent it from being displayed empty\n",
        "        return\n",
        "\n",
        "    feature_importance = np.mean(np.abs(weights), axis=0)\n",
        "\n",
        "    # Sort features by importance\n",
        "    indices = np.argsort(feature_importance)\n",
        "    sorted_feature_names = [feature_names[i] for i in indices]\n",
        "    sorted_importance = feature_importance[indices]\n",
        "\n",
        "    # Create a horizontal bar chart\n",
        "    bars = plt.barh(range(len(sorted_feature_names)), sorted_importance,\n",
        "                    color=plt.cm.viridis(np.linspace(0, 1, len(sorted_feature_names))))\n",
        "\n",
        "    # Add importance values as text\n",
        "    for i, (bar, value) in enumerate(zip(bars, sorted_importance)):\n",
        "        plt.text(value + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                 f'{value:.4f}', va='center', fontsize=10)\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.xlabel('Mean Absolute Weight', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
        "    plt.title('Feature Importance in Split Learning Model (Client Layer 1)', fontsize=14, fontweight='bold')\n",
        "    plt.yticks(range(len(sorted_feature_names)), sorted_feature_names)\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Add explanatory text\n",
        "    plt.figtext(0.5, 0.01,\n",
        "                \"Feature importance based on mean absolute weights from the first layer of the client model.\\n\"\n",
        "                \"Higher values indicate stronger influence on the model's decisions.\",\n",
        "                ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.05, 1, 0.95]) # Adjust for the text box\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'feature_importance.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "9-pJZgCOY12m"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creates and saves a t-SNE visualization of the feature space after transformation\n",
        "    by the client model.\n",
        "\n",
        "Purpose:\n",
        "Visualize how the model transforms high-dimensional data.\n",
        "Key Features:\n",
        "\n",
        "Data Subsampling: Processes first 20 batches for efficiency.\n",
        "\n",
        "Class-Source Coding: Shapes (circles/X) for train/test, colors for classes.\n",
        "\n",
        "Perplexity Adjustment: Avoids errors with small datasets.\n",
        "\n",
        "Cluster Interpretation: Text explains point proximity meaning.\n",
        "    "
      ],
      "metadata": {
        "id": "9YbBkkJ7dhPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def visualize_feature_space(train_dataloader, test_dataloader, client_model, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves a t-SNE visualization of the feature space after transformation\n",
        "    by the client model.\n",
        "\n",
        "    Args:\n",
        "        train_dataloader: DataLoader containing training data\n",
        "        test_dataloader: DataLoader containing test data\n",
        "        client_model: Trained client PyTorch model\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    # Ensure dataloaders and client_model are not None\n",
        "    if train_dataloader is None or test_dataloader is None or client_model is None:\n",
        "        print(\"Cannot plot t-SNE visualization: Dataloaders or client model not available.\")\n",
        "        return\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    client_model.eval()\n",
        "\n",
        "    # Initialize lists to store activations and labels\n",
        "    activations = []\n",
        "    labels = []\n",
        "    sources = []  # To track if the data is from training or testing set\n",
        "\n",
        "    # Process a subset of training data (to avoid overwhelming t-SNE)\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, batch_labels) in enumerate(train_dataloader):\n",
        "            if i >= 20:  # Increased limit for potentially better t-SNE representation\n",
        "                break\n",
        "            # Ensure inputs are on the correct device before passing to model\n",
        "            inputs = inputs.to(next(client_model.parameters()).device)\n",
        "            batch_activations = client_model(inputs).cpu().numpy()\n",
        "            activations.append(batch_activations)\n",
        "            labels.append(batch_labels.cpu().numpy())\n",
        "            sources.extend(['train'] * len(batch_labels))\n",
        "\n",
        "    # Process a subset of testing data\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, batch_labels) in enumerate(test_dataloader):\n",
        "            if i >= 20:  # Increased limit for potentially better t-SNE representation\n",
        "                break\n",
        "            # Ensure inputs are on the correct device before passing to model\n",
        "            inputs = inputs.to(next(client_model.parameters()).device)\n",
        "            batch_activations = client_model(inputs).cpu().numpy()\n",
        "            activations.append(batch_activations)\n",
        "            labels.append(batch_labels.cpu().numpy())\n",
        "            sources.extend(['test'] * len(batch_labels))\n",
        "\n",
        "    # Combine all data\n",
        "    if not activations:\n",
        "        print(\"No data collected for t-SNE visualization. Skipping plot.\")\n",
        "        return\n",
        "\n",
        "    activations = np.vstack(activations)\n",
        "    labels = np.concatenate(labels)\n",
        "\n",
        "    # Handle case with insufficient samples for t-SNE\n",
        "    if len(activations) < max(30, len(np.unique(labels)) + 1) and len(activations) > 1: # t-SNE requires samples > perplexity (default 30) and > num_classes\n",
        "        print(f\"Insufficient data points ({len(activations)}) for t-SNE visualization. Need at least {max(30, len(np.unique(labels)) + 1)} samples. Skipping plot.\")\n",
        "        return\n",
        "    elif len(activations) <= 1:\n",
        "         print(f\"Only {len(activations)} data point(s) available for t-SNE visualization. Need at least 2. Skipping plot.\")\n",
        "         return\n",
        "\n",
        "\n",
        "    # Apply t-SNE for dimensionality reduction to 2D\n",
        "    print(\"Applying t-SNE dimensionality reduction...\")\n",
        "    # Adjust perplexity based on the number of samples if needed\n",
        "    perplexity_val = min(30, len(activations) - 1) if len(activations) > 1 else 1\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_val)\n",
        "    try:\n",
        "        activations_2d = tsne.fit_transform(activations)\n",
        "    except ValueError as ve:\n",
        "        print(f\"Error during t-SNE transformation: {ve}. This might happen if data is too uniform or insufficient samples for perplexity.\")\n",
        "        print(\"Skipping t-SNE visualization.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # Create the visualization\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Set up the color scheme for classes\n",
        "    # Ensure there are enough colors for the unique labels\n",
        "    unique_labels = np.unique(labels)\n",
        "    if len(unique_labels) > len(mcolors.CSS4_COLORS): # Fallback if too many unique labels\n",
        "        colors = plt.cm.get_cmap('viridis', len(unique_labels))(np.arange(len(unique_labels)))\n",
        "    else:\n",
        "        # Use a fixed set of colors for up to 2 classes (Safe/Risky)\n",
        "        class_colors = ['#1f77b4', '#ff7f0e'] # blue for class 0, orange for class 1\n",
        "        colors = [class_colors[int(label)] for label in unique_labels]\n",
        "\n",
        "\n",
        "    source_markers = {'train': 'o', 'test': 'X'}\n",
        "\n",
        "    # Create scatter plot with different colors for classes and markers for train/test\n",
        "    for label in unique_labels:\n",
        "        # Ensure label is an integer index for class_colors if using the fixed set\n",
        "        label_int = int(label)\n",
        "\n",
        "        for source in ['train', 'test']:\n",
        "            # Get indices matching both class and source\n",
        "            indices = np.where((labels == label) & (np.array(sources) == source))[0]\n",
        "            if len(indices) == 0:\n",
        "                continue\n",
        "\n",
        "            # Determine the color for this label\n",
        "            color_for_label = colors[list(unique_labels).index(label)]\n",
        "\n",
        "\n",
        "            plt.scatter(\n",
        "                activations_2d[indices, 0],\n",
        "                activations_2d[indices, 1],\n",
        "                c=[color_for_label] * len(indices),\n",
        "                marker=source_markers[source],\n",
        "                s=50 if source == 'train' else 100,\n",
        "                alpha=0.7 if source == 'train' else 0.8,\n",
        "                edgecolors='w' if source == 'train' else 'k',\n",
        "                linewidth=0.5 if source == 'train' else 1.0,\n",
        "                label=f\"Class {label_int} ({source})\"\n",
        "            )\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title('t-SNE Visualization of Client Model Feature Space', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('t-SNE Component 1', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('t-SNE Component 2', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Add legend with custom handles (recreate based on actual unique labels and sources found)\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = []\n",
        "    for label in unique_labels:\n",
        "         label_int = int(label)\n",
        "         color_for_label = colors[list(unique_labels).index(label)]\n",
        "         if f\"Class {label_int} (Train)\" in [l.get_label() for l in plt.gca().get_legend_handles_labels()[0]]:\n",
        "             legend_elements.append(Line2D([0], [0], marker=source_markers['train'], color='w', markerfacecolor=color_for_label,\n",
        "                                            label=f'Class {label_int} (Train)', markersize=10))\n",
        "         if f\"Class {label_int} (Test)\" in [l.get_label() for l in plt.gca().get_legend_handles_labels()[0]]:\n",
        "             legend_elements.append(Line2D([0], [0], marker=source_markers['test'], color='w', markerfacecolor=color_for_label,\n",
        "                                            markeredgecolor='k', label=f'Class {label_int} (Test)', markersize=10))\n",
        "\n",
        "    plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
        "\n",
        "\n",
        "    # Add grid\n",
        "    plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "    # Add descriptive text\n",
        "    plt.figtext(0.5, 0.01,\n",
        "                \"This t-SNE visualization shows how the client model transforms input features.\\n\"\n",
        "                \"Points that are close together represent similar patterns as detected by the model.\",\n",
        "                ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])  # Adjust for text box\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'tsne_visualization.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "cKgVIuOxY5kR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creates and saves a visualization summarizing model performance metrics.\n",
        "\n",
        " Purpose:\n",
        "Consolidate key metrics into one view.\n",
        "Key Features:\n",
        "\n",
        "Grid Layout: Combines table, distributions, and bar charts.\n",
        "\n",
        "Adaptive Tables: Handles missing classes gracefully.\n",
        "\n",
        "Class Distribution: Bar chart with sample counts.\n",
        "\n",
        "Metric Comparisons: Grouped bars for precision/recall/F1."
      ],
      "metadata": {
        "id": "6BOGKO8Udj_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_performance_summary(y_true, y_pred, save_path):\n",
        "    \"\"\"\n",
        "    Creates and saves a visualization summarizing model performance metrics.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels from test set\n",
        "        y_pred: Predicted labels from model\n",
        "        save_path: Directory to save the plot\n",
        "    \"\"\"\n",
        "    # Ensure there are enough data points and at least two classes in y_true\n",
        "    if len(y_true) < 2 or len(np.unique(y_true)) < 2:\n",
        "        print(\"Cannot create performance summary: Insufficient data or only one class in test set.\")\n",
        "        # Create a placeholder figure to avoid errors\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "        ax.text(0.5, 0.5, \"Insufficient data for summary table.\", horizontalalignment='center', verticalalignment='center')\n",
        "        ax.axis('off')\n",
        "        plt.title(\"Performance Summary (Insufficient Data)\")\n",
        "        os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "        plt.savefig(os.path.join(save_path, 'performance_summary.png'), dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        return\n",
        "\n",
        "\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "    # Extract metrics for each class\n",
        "    class_metrics = {}\n",
        "    # Handle cases where a class might not be present in the predictions or true labels\n",
        "    classes_in_report = [str(c) for c in np.unique(y_true)] # Use true labels to define classes\n",
        "    for cls in classes_in_report:\n",
        "         class_metrics[cls] = {\n",
        "             'Precision': report[cls]['precision'] if cls in report else 0.0,\n",
        "             'Recall': report[cls]['recall'] if cls in report else 0.0,\n",
        "             'F1-Score': report[cls]['f1-score'] if cls in report else 0.0,\n",
        "             'Support': report[cls]['support'] if cls in report else 0\n",
        "         }\n",
        "\n",
        "    # Create figure with grid layout\n",
        "    fig = plt.figure(figsize=(14, 10))\n",
        "    gs = GridSpec(2, 2, figure=fig)\n",
        "\n",
        "    # 1. Create a table with model performance metrics\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax1.axis('tight')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Create table data\n",
        "    table_data = [\n",
        "        ['Metric', 'Overall', 'Class 0 (Safe)', 'Class 1 (Risky)'],\n",
        "        ['Accuracy', f\"{accuracy_score(y_true, y_pred):.4f}\", '-', '-'], # Calculate accuracy directly\n",
        "        ['Precision', f\"{report['weighted avg']['precision']:.4f}\" if 'weighted avg' in report else '-',\n",
        "         f\"{class_metrics['0']['Precision']:.4f}\" if '0' in class_metrics else '-',\n",
        "         f\"{class_metrics['1']['Precision']:.4f}\" if '1' in class_metrics else '-'],\n",
        "        ['Recall', f\"{report['weighted avg']['recall']:.4f}\" if 'weighted avg' in report else '-',\n",
        "         f\"{class_metrics['0']['Recall']:.4f}\" if '0' in class_metrics else '-',\n",
        "         f\"{class_metrics['1']['Recall']:.4f}\" if '1' in class_metrics else '-'],\n",
        "        ['F1-Score', f\"{report['weighted avg']['f1-score']:.4f}\" if 'weighted avg' in report else '-',\n",
        "         f\"{class_metrics['0']['F1-Score']:.4f}\" if '0' in class_metrics else '-',\n",
        "         f\"{class_metrics['1']['F1-Score']:.4f}\" if '1' in class_metrics else '-'],\n",
        "        ['Support', f\"{report['weighted avg']['support']:.0f}\" if 'weighted avg' in report else '-',\n",
        "         f\"{class_metrics['0']['Support']:.0f}\" if '0' in class_metrics else '-',\n",
        "         f\"{class_metrics['1']['Support']:.0f}\" if '1' in class_metrics else '-']\n",
        "    ]\n",
        "\n",
        "    # Create the table\n",
        "    table = ax1.table(cellText=table_data, cellLoc='center', loc='center')\n",
        "\n",
        "    # Style the table\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1.2, 1.2) # Adjust table size\n",
        "\n",
        "    # Apply bold font to header row\n",
        "    # Corrected attribute access from .cbox to .cells\n",
        "    for (row, col), cell in table.get_celld().items():\n",
        "        if row == 0:\n",
        "            cell.set_text_props(fontweight='bold')\n",
        "\n",
        "    ax1.set_title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
        "\n",
        "\n",
        "    # 2. Create a bar chart for class distribution in the test set\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    # Ensure class names match the potential unique labels\n",
        "    class_names = ['Safe (0)', 'Risky (1)'] # Assuming binary classification 0/1\n",
        "    class_counts = pd.Series(y_true).value_counts().sort_index()\n",
        "    # Only plot for the classes that are actually present\n",
        "    present_class_names = [name for i, name in enumerate(class_names) if i in class_counts.index]\n",
        "    present_class_counts = [count for i, count in class_counts.items() if i in class_counts.index]\n",
        "    present_colors = ['skyblue' if i == 0 else 'salmon' for i in class_counts.index]\n",
        "\n",
        "\n",
        "    bars = ax2.bar(present_class_names, present_class_counts, color=present_colors)\n",
        "    ax2.set_ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('Test Set Class Distribution', fontsize=14, fontweight='bold')\n",
        "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    # Add counts on top of bars\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center') # va: vertical alignment\n",
        "\n",
        "    # 3. Create a bar chart for Precision, Recall, F1-Score by Class\n",
        "    ax3 = fig.add_subplot(gs[1, :]) # Span across both columns in the second row\n",
        "\n",
        "    # Filter metrics to only include classes present in the test set\n",
        "    metrics_data = {\n",
        "        'Metric': ['Precision', 'Recall', 'F1-Score'],\n",
        "    }\n",
        "    if '0' in class_metrics:\n",
        "        metrics_data['Class 0 (Safe)'] = [class_metrics['0']['Precision'], class_metrics['0']['Recall'], class_metrics['0']['F1-Score']]\n",
        "    if '1' in class_metrics:\n",
        "        metrics_data['Class 1 (Risky)'] = [class_metrics['1']['Precision'], class_metrics['1']['Recall'], class_metrics['1']['F1-Score']]\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "    # Plotting grouped bar chart\n",
        "    # Exclude the 'Metric' column when plotting\n",
        "    columns_to_plot = [col for col in metrics_df.columns if col != 'Metric']\n",
        "    if columns_to_plot: # Only plot if there are metrics columns\n",
        "        metrics_df.plot(x='Metric', y=columns_to_plot, kind='bar', ax=ax3, colormap='viridis', rot=0)\n",
        "        ax3.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "        ax3.set_title('Precision, Recall, and F1-Score by Class', fontsize=14, fontweight='bold')\n",
        "        ax3.legend(title='Class', loc='upper left')\n",
        "        ax3.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Add score values on top of bars\n",
        "        for container in ax3.containers:\n",
        "            ax3.bar_label(container, fmt='%.2f', label_type='edge')\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, \"Insufficient data for metrics bar chart.\", horizontalalignment='center', verticalalignment='center')\n",
        "        ax3.axis('off')\n",
        "\n",
        "\n",
        "    plt.suptitle('Comprehensive Model Performance Summary', fontsize=18, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.97]) # Adjust layout to make room for suptitle\n",
        "    os.makedirs(save_path, exist_ok=True) # Create directory if it doesn't exist\n",
        "    plt.savefig(os.path.join(save_path, 'performance_summary.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "nFCfv7VQZHG6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function to plot different graphs\n",
        "\n",
        "Workflow:\n",
        "\n",
        "Sanity Checks: Validates training results exist.\n",
        "\n",
        "Directory Setup: Creates output folder for plots.\n",
        "\n",
        "Plot Sequencing: Generates 6 complementary visualizations.\n",
        "\n",
        "Error Handling: Skips incompatible plots (e.g., ROC with 1 class)."
      ],
      "metadata": {
        "id": "zTE4kIBXdmHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Part 2: Visualization ---\n",
        "\n",
        "# --- All Imports for Visualization ---\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "import torch # Needed for client_model and checking device\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Visualization Execution (Part 2) ---\n",
        "# This block assumes the variables from Part 1 are available in the environment.\n",
        "\n",
        "print(\"--- Starting V2V Split Learning Visualization (Part 2) ---\")\n",
        "\n",
        "# Check if the necessary variables from Part 1 are available and valid\n",
        "if 'training_losses' in locals() and training_losses is not None and \\\n",
        "   'test_losses' in locals() and test_losses is not None and \\\n",
        "   'epochs_list' in locals() and epochs_list is not None and \\\n",
        "   'all_test_labels' in locals() and all_test_labels is not None and \\\n",
        "   'all_test_predictions' in locals() and all_test_predictions is not None and \\\n",
        "   'trained_client_model' in locals() and trained_client_model is not None and \\\n",
        "   'train_dataloader' in locals() and train_dataloader is not None and \\\n",
        "   'test_dataloader' in locals() and test_dataloader is not None and \\\n",
        "   'feature_names' in locals() and feature_names is not None and \\\n",
        "   'PLOT_SAVE_DIR' in locals() and PLOT_SAVE_DIR is not None:\n",
        "\n",
        "    # Create directory for plots if it doesn't exist (redundant but safe)\n",
        "    os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "    print(f\"Saving plots to: {os.path.abspath(PLOT_SAVE_DIR)}\")\n",
        "\n",
        "\n",
        "    # Plot learning curves\n",
        "    print(\"Generating learning curves plot...\")\n",
        "    plot_learning_curves(training_losses, test_losses, epochs_list, PLOT_SAVE_DIR)\n",
        "    print(f\"Learning curves plot saved to {os.path.join(PLOT_SAVE_DIR, 'learning_curves.png')}\")\n",
        "\n",
        "    # Plot enhanced confusion matrix\n",
        "    print(\"Generating enhanced confusion matrix plot...\")\n",
        "    plot_enhanced_confusion_matrix(all_test_labels, all_test_predictions, PLOT_SAVE_DIR)\n",
        "    print(f\"Confusion matrix plot saved to {os.path.join(PLOT_SAVE_DIR, 'confusion_matrix.png')}\")\n",
        "\n",
        "    # Plot ROC and Precision-Recall curves\n",
        "    # Ensure there are at least two classes in the test labels before plotting ROC/PR\n",
        "    if len(np.unique(all_test_labels)) >= 2:\n",
        "        print(\"Generating ROC curve plot...\")\n",
        "        plot_roc_curve(all_test_labels, all_test_predictions, PLOT_SAVE_DIR)\n",
        "        print(f\"ROC curve plot saved to {os.path.join(PLOT_SAVE_DIR, 'roc_curve.png')}\")\n",
        "\n",
        "        print(\"Generating Precision-Recall curve plot...\")\n",
        "        plot_precision_recall_curve(all_test_labels, all_test_predictions, PLOT_SAVE_DIR)\n",
        "        print(f\"Precision-Recall curve plot saved to {os.path.join(PLOT_SAVE_DIR, 'precision_recall_curve.png')}\")\n",
        "    else:\n",
        "        print(\"Skipping ROC and Precision-Recall plots: Test set contains only one class.\")\n",
        "\n",
        "\n",
        "    # Feature analysis (requires client_model and feature_names)\n",
        "    print(\"Generating feature importance plot...\")\n",
        "    # Pass the trained_client_model from Part 1\n",
        "    analyze_feature_importance(trained_client_model, feature_names, PLOT_SAVE_DIR)\n",
        "    print(f\"Feature importance plot saved to {os.path.join(PLOT_SAVE_DIR, 'feature_importance.png')}\")\n",
        "\n",
        "\n",
        "    # t-SNE visualization (requires dataloaders and client_model)\n",
        "    print(\"Generating t-SNE visualization plot...\")\n",
        "    # Pass the dataloaders and trained_client_model from Part 1\n",
        "    visualize_feature_space(train_dataloader, test_dataloader, trained_client_model, PLOT_SAVE_DIR)\n",
        "    print(f\"t-SNE visualization plot saved to {os.path.join(PLOT_SAVE_DIR, 'tsne_visualization.png')}\")\n",
        "\n",
        "\n",
        "    # Performance summary\n",
        "    print(\"Generating performance summary plot...\")\n",
        "    create_performance_summary(all_test_labels, all_test_predictions, PLOT_SAVE_DIR)\n",
        "    print(f\"Performance summary plot saved to {os.path.join(PLOT_SAVE_DIR, 'performance_summary.png')}\")\n",
        "\n",
        "    print(\"\\n--- Part 2: All Visualizations Generated ---\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Part 2: Training Results Not Available ---\")\n",
        "    print(\"Skipping visualization. Ensure Part 1 ran successfully.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un7eSziDEovQ",
        "outputId": "f77c27d3-a864-4686-84a9-22cf7b349434"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting V2V Split Learning Visualization (Part 2) ---\n",
            "Saving plots to: /content/training_plots\n",
            "Generating learning curves plot...\n",
            "Learning curves plot saved to training_plots/learning_curves.png\n",
            "Generating enhanced confusion matrix plot...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix plot saved to training_plots/confusion_matrix.png\n",
            "Generating ROC curve plot...\n",
            "ROC curve plot saved to training_plots/roc_curve.png\n",
            "Generating Precision-Recall curve plot...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-e33e1f9d0b8d>:59: RuntimeWarning: divide by zero encountered in divide\n",
            "  y = (f1 * x) / (2 * x - f1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision-Recall curve plot saved to training_plots/precision_recall_curve.png\n",
            "Generating feature importance plot...\n",
            "Feature importance plot saved to training_plots/feature_importance.png\n",
            "Generating t-SNE visualization plot...\n",
            "Applying t-SNE dimensionality reduction...\n",
            "t-SNE visualization plot saved to training_plots/tsne_visualization.png\n",
            "Generating performance summary plot...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance summary plot saved to training_plots/performance_summary.png\n",
            "\n",
            "--- Part 2: All Visualizations Generated ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtWiS0QpXq97"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}